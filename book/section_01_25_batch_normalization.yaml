# section_01_25_batch_normalization.yaml

---
document_info:
  chapter: "01"
  section: "25"
  title: "Batch Normalization"
  version: "1.0.0"
  author: "Raghav Dinesh"
  github: "github.com/raghavpoonia"
  license: "MIT"
  created: "2025-12-31"
  estimated_pages: 5
  tags: ["batch-normalization", "normalization", "internal-covariate-shift", "training-acceleration", "regularization"]

# ============================================================================
# SECTION 1.25: BATCH NORMALIZATION
# ============================================================================

section_01_25_batch_normalization:
  
  # --------------------------------------------------------------------------
  # Overview and Context
  # --------------------------------------------------------------------------
  
  overview: |
    Batch Normalization (BatchNorm) is one of the most important innovations in deep learning. 
    Introduced in 2015, it dramatically accelerates training, enables higher learning rates, 
    and acts as a regularizer. Before BatchNorm, training very deep networks was challenging 
    and unstable. BatchNorm made it routine.
    
    The core idea is simple: normalize activations within each mini-batch to have mean 0 
    and variance 1, then scale and shift with learned parameters. This addresses internal 
    covariate shift - the problem that layer inputs' distributions change during training, 
    forcing later layers to constantly adapt.
    
    This section covers:
    - Internal covariate shift problem
    - Batch normalization algorithm
    - Training vs inference modes
    - Benefits (faster training, regularization, higher learning rates)
    - Placement in network architecture
    - Variants and alternatives
    
    For security ML:
    1. Faster training = quicker deployment against threats
    2. More stable training = reliable model updates
    3. Better generalization = robust detection
    4. Standard in modern architectures
  
  why_this_matters: |
    Impact on deep learning:
    - Enabled training of very deep networks (100+ layers)
    - Reduced training time by 14x in original paper
    - Became standard component in modern architectures
    - Nearly universal in CNNs, Transformers, etc.
    
    Security context:
    - Faster training = rapid response to evolving threats
    - Stable training = reliable production systems
    - Better generalization = robust to attack variations
    - Industry standard (used in production models)
    
    Why learn BatchNorm:
    - Critical for understanding modern deep learning
    - Used in virtually all state-of-the-art models
    - Impacts training dynamics significantly
    - Essential for implementing custom architectures
  
  # --------------------------------------------------------------------------
  # Core Concept 1: The Problem - Internal Covariate Shift
  # --------------------------------------------------------------------------
  
  internal_covariate_shift:
    
    problem_statement: |
      During training, network parameters constantly change
      → Distribution of inputs to each layer keeps shifting
      → Later layers must adapt to changing distributions
      → Slows down training, requires careful initialization
    
    example: |
      3-layer network during training:
      
      Iteration 1:
      Layer 1 output: mean=0, std=1
      Layer 2 learns with this distribution
      
      Iteration 100:
      Layer 1 parameters changed
      Layer 1 output: mean=5, std=3  ← Distribution shifted!
      Layer 2 must adapt to new distribution
      
      Iteration 200:
      Layer 1 output: mean=-2, std=0.5  ← Shifted again!
      Layer 2 adapts again
      
      Layer 2 constantly chasing moving target
    
    consequences:
      slow_training:
        - "Each layer adapts to changing inputs"
        - "Can't learn efficiently"
      
      careful_initialization_required:
        - "Bad initialization → exploding/vanishing gradients"
        - "Must use specific schemes (Xavier, He)"
      
      low_learning_rates:
        - "High learning rate → unstable training"
        - "Forced to use small learning rate → slow"
      
      gradient_problems:
        - "Activations can saturate (sigmoid, tanh)"
        - "Gradients vanish → deep layers don't learn"
    
    covariate_shift_analogy: |
      Imagine learning to catch a ball
      But the ball's weight, size, and bounce change randomly
      Much harder to learn!
      
      vs
      
      Ball properties consistent
      Can learn catching strategy efficiently
      
      BatchNorm: Makes each layer's inputs consistent
  
  # --------------------------------------------------------------------------
  # Core Concept 2: Batch Normalization Algorithm
  # --------------------------------------------------------------------------
  
  batch_norm_algorithm:
    
    high_level_idea: |
      For each mini-batch:
      1. Normalize activations: mean=0, variance=1
      2. Scale and shift: Allow network to undo normalization if needed
      
      Ensures each layer receives inputs from stable distribution
    
    algorithm_during_training: |
      Given: Mini-batch of activations B = {x₁, ..., xₘ}
      Parameters: γ (scale), β (shift) - learned during training
      
      Step 1: Compute batch mean
      μ_B = (1/m) Σᵢ xᵢ
      
      Step 2: Compute batch variance
      σ²_B = (1/m) Σᵢ (xᵢ - μ_B)²
      
      Step 3: Normalize
      x̂ᵢ = (xᵢ - μ_B) / √(σ²_B + ε)
      
      Step 4: Scale and shift
      yᵢ = γx̂ᵢ + β
      
      Where ε = 1e-5 (small constant for numerical stability)
    
    learnable_parameters: |
      γ (gamma): Scale parameter
      β (beta): Shift parameter
      
      These are learned via backpropagation
      
      Why needed:
      - Network might need different mean/variance for optimal performance
      - If optimal is original distribution: γ=σ_B, β=μ_B recovers it
      - Gives network flexibility
    
    example_calculation: |
      Mini-batch: B = [1, 2, 3, 4, 5]
      
      Step 1: Mean
      μ_B = (1+2+3+4+5)/5 = 3
      
      Step 2: Variance
      σ²_B = ((1-3)² + (2-3)² + (3-3)² + (4-3)² + (5-3)²)/5
           = (4 + 1 + 0 + 1 + 4)/5 = 2
      
      Step 3: Normalize
      x̂ = (B - 3) / √(2 + 1e-5)
         = [-2, -1, 0, 1, 2] / 1.414
         = [-1.41, -0.71, 0, 0.71, 1.41]
      
      Step 4: Scale and shift (γ=2, β=1)
      y = 2 × x̂ + 1
        = [-1.82, -0.42, 1, 2.42, 3.82]
    
    where_to_apply: |
      Apply BatchNorm to layer activations
      
      Typical placement:
      Linear/Conv → BatchNorm → Activation (ReLU)
      
      Or:
      Linear/Conv → Activation (ReLU) → BatchNorm
      
      Most common: Before activation
  
  # --------------------------------------------------------------------------
  # Core Concept 3: Training vs Inference
  # --------------------------------------------------------------------------
  
  training_vs_inference:
    
    training_mode: |
      Use batch statistics:
      - Compute μ_B and σ²_B from current mini-batch
      - Normalize using these batch statistics
      - Update running averages (for inference)
    
    running_statistics: |
      During training, maintain running averages:
      
      running_mean = momentum × running_mean + (1-momentum) × μ_B
      running_var = momentum × running_var + (1-momentum) × σ²_B
      
      Typical momentum: 0.9 or 0.99
      
      These accumulate statistics over all training batches
    
    inference_mode: |
      Problem at inference:
      - May have single sample (batch size = 1)
      - Batch statistics meaningless for single sample
      
      Solution: Use running statistics from training
      
      Normalize using:
      x̂ = (x - running_mean) / √(running_var + ε)
      y = γx̂ + β
      
      Fixed statistics (no batch dependency)
    
    why_different_modes: |
      Training:
      - Have mini-batches → use batch statistics
      - Provides regularization (noise from batch sampling)
      
      Inference:
      - May have single samples
      - Need deterministic predictions
      - Use population statistics (running averages)
    
    mode_switching: |
      Most frameworks (PyTorch, TensorFlow):
      
      model.train()  # Training mode: use batch stats
      model.eval()   # Inference mode: use running stats
      
      Critical to set correctly!
  
  # --------------------------------------------------------------------------
  # Core Concept 4: Benefits of Batch Normalization
  # --------------------------------------------------------------------------
  
  benefits:
    
    faster_training:
      observation: "Training converges 14x faster (original paper)"
      
      reason: |
        - Reduces internal covariate shift
        - Each layer receives stable input distribution
        - Can use higher learning rates
      
      example: |
        Without BatchNorm: 100 epochs to converge
        With BatchNorm: 7 epochs to converge
    
    higher_learning_rates:
      enabled: "Can use learning rates 10x higher"
      
      why: |
        - Normalization prevents exploding activations
        - Gradient flow more stable
        - Less sensitive to initialization
      
      typical: |
        Without BatchNorm: lr = 0.01
        With BatchNorm: lr = 0.1 (works fine!)
    
    regularization_effect:
      behavior: "Acts as regularizer, reduces overfitting"
      
      mechanism: |
        - Each sample normalized using batch statistics
        - Batch statistics have noise (different batches)
        - Adds stochasticity → regularization
        - Similar effect to dropout
      
      consequence: "May not need dropout with BatchNorm"
    
    reduces_gradient_issues:
      vanishing_gradients: "Less likely (normalized activations)"
      exploding_gradients: "Prevented by normalization"
      
      enables_deeper_networks: "Can train 100+ layer networks"
    
    less_sensitive_to_initialization:
      without_batchnorm: "Careful initialization required (Xavier, He)"
      with_batchnorm: "Works with random initialization"
      
      reason: "Normalization corrects poor initialization"
  
  # --------------------------------------------------------------------------
  # Practical Implementation
  # --------------------------------------------------------------------------
  
  practical_implementation: |
    import numpy as np
    
    class BatchNorm1D:
        """Batch Normalization for 1D data (fully connected layers)"""
        
        def __init__(self, num_features, momentum=0.9, epsilon=1e-5):
            """
            Args:
                num_features: Number of features (neurons in layer)
                momentum: Momentum for running statistics
                epsilon: Small constant for numerical stability
            """
            self.num_features = num_features
            self.momentum = momentum
            self.epsilon = epsilon
            
            # Learnable parameters
            self.gamma = np.ones(num_features)   # Scale
            self.beta = np.zeros(num_features)   # Shift
            
            # Running statistics (for inference)
            self.running_mean = np.zeros(num_features)
            self.running_var = np.ones(num_features)
            
            # Training mode flag
            self.training = True
        
        def forward(self, x):
            """
            Forward pass
            
            Args:
                x: Input (batch_size, num_features)
            
            Returns:
                Normalized and scaled output
            """
            if self.training:
                # Training mode: use batch statistics
                batch_mean = np.mean(x, axis=0)
                batch_var = np.var(x, axis=0)
                
                # Normalize
                x_normalized = (x - batch_mean) / np.sqrt(batch_var + self.epsilon)
                
                # Update running statistics
                self.running_mean = (self.momentum * self.running_mean + 
                                    (1 - self.momentum) * batch_mean)
                self.running_var = (self.momentum * self.running_var + 
                                   (1 - self.momentum) * batch_var)
                
                # Cache for backward pass
                self.cache = (x, x_normalized, batch_mean, batch_var)
            else:
                # Inference mode: use running statistics
                x_normalized = ((x - self.running_mean) / 
                               np.sqrt(self.running_var + self.epsilon))
            
            # Scale and shift
            out = self.gamma * x_normalized + self.beta
            
            return out
        
        def backward(self, dout):
            """
            Backward pass
            
            Args:
                dout: Gradient from next layer
            
            Returns:
                Gradient w.r.t. input
            """
            x, x_normalized, batch_mean, batch_var = self.cache
            batch_size = x.shape[0]
            
            # Gradients w.r.t. learnable parameters
            self.dgamma = np.sum(dout * x_normalized, axis=0)
            self.dbeta = np.sum(dout, axis=0)
            
            # Gradient w.r.t. normalized input
            dx_normalized = dout * self.gamma
            
            # Gradient w.r.t. variance
            dvar = np.sum(dx_normalized * (x - batch_mean) * 
                         -0.5 * (batch_var + self.epsilon)**(-1.5), axis=0)
            
            # Gradient w.r.t. mean
            dmean = (np.sum(dx_normalized * -1 / np.sqrt(batch_var + self.epsilon), axis=0) +
                    dvar * np.sum(-2 * (x - batch_mean), axis=0) / batch_size)
            
            # Gradient w.r.t. input
            dx = (dx_normalized / np.sqrt(batch_var + self.epsilon) +
                 dvar * 2 * (x - batch_mean) / batch_size +
                 dmean / batch_size)
            
            return dx
        
        def train(self):
            """Set to training mode"""
            self.training = True
        
        def eval(self):
            """Set to inference mode"""
            self.training = False
    
    # ========================================================================
    # USAGE EXAMPLE
    # ========================================================================
    
    # Create BatchNorm layer
    bn = BatchNorm1D(num_features=10)
    
    # Training
    bn.train()
    for epoch in range(10):
        # Sample mini-batch
        x_batch = np.random.randn(32, 10)
        
        # Forward pass
        output = bn.forward(x_batch)
        
        # Backward pass (in actual training)
        # dx = bn.backward(dout)
    
    # Inference
    bn.eval()
    x_test = np.random.randn(1, 10)  # Single sample
    output_test = bn.forward(x_test)  # Uses running statistics
  
  # --------------------------------------------------------------------------
  # Placement in Architecture
  # --------------------------------------------------------------------------
  
  placement:
    
    typical_pattern: |
      Fully Connected Network:
      Linear → BatchNorm → Activation (ReLU)
      
      Or:
      Linear → Activation (ReLU) → BatchNorm
      
      Most common: Before activation
    
    full_network_example: |
      Input
      ↓
      Linear Layer 1
      ↓
      BatchNorm 1
      ↓
      ReLU
      ↓
      Linear Layer 2
      ↓
      BatchNorm 2
      ↓
      ReLU
      ↓
      Linear Layer 3 (output)
      ↓
      Softmax
      
      Note: Usually don't apply BatchNorm to output layer
    
    convolutional_networks: |
      Conv → BatchNorm → ReLU
      
      BatchNorm operates on channels:
      - Compute mean/var per channel
      - Across batch and spatial dimensions
      
      Example: Conv output (batch=32, channels=64, height=28, width=28)
      → BatchNorm computes 64 means and 64 variances
  
  # --------------------------------------------------------------------------
  # Variants and Alternatives
  # --------------------------------------------------------------------------
  
  variants:
    
    layer_normalization:
      difference: "Normalize across features (not batch)"
      
      when_to_use: |
        - Recurrent networks (RNNs, LSTMs)
        - Transformers
        - When batch size varies or is 1
      
      formula: |
        Normalize each sample independently
        μ = mean across features for sample i
        σ² = variance across features for sample i
    
    instance_normalization:
      difference: "Normalize each sample and channel independently"
      
      when_to_use: "Style transfer, GANs"
    
    group_normalization:
      difference: "Divide channels into groups, normalize within groups"
      
      when_to_use: "Small batch sizes (batch norm unstable)"
    
    comparison: |
      BatchNorm: Normalize across batch dimension
      LayerNorm: Normalize across feature dimension
      InstanceNorm: Normalize across spatial dimensions
      GroupNorm: Normalize across channel groups
  
  # --------------------------------------------------------------------------
  # Key Takeaways
  # --------------------------------------------------------------------------
  
  key_takeaways:
    
    conceptual_understanding:
      - "BatchNorm: Normalize activations to mean=0, var=1"
      - "Internal covariate shift: Input distributions change during training"
      - "Scale and shift: Learnable γ and β allow flexibility"
      - "Training: Use batch statistics"
      - "Inference: Use running statistics (population estimates)"
      - "Benefits: Faster training, higher learning rates, regularization"
    
    practical_skills:
      - "Implement BatchNorm from scratch"
      - "Understand training vs inference modes"
      - "Place BatchNorm correctly in architecture"
      - "Know when to use alternatives (LayerNorm, etc.)"
      - "Set training/eval modes properly"
    
    security_mindset:
      - "Faster training = quicker deployment against threats"
      - "Stable training = reliable production updates"
      - "Standard in modern architectures (CNNs, Transformers)"
      - "Regularization effect helps generalization"
    
    remember_this:
      - "BatchNorm = normalize to mean=0, var=1, then scale/shift"
      - "Training: batch statistics, Inference: running statistics"
      - "Place before or after activation (typically before)"
      - "Enables higher learning rates (10x)"
      - "Acts as regularizer (may replace dropout)"
    
    next_steps:
      - "Next section: Model Deployment Basics"
      - "You now understand modern training techniques!"
      - "BatchNorm critical for deep learning success"

---
