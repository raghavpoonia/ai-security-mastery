# section_02_06_backprop_implementation.yaml
---
document_info:
  chapter: "02"
  section: "06"
  title: "Backpropagation Implementation"
  version: "1.0.0"
  author: "Raghav Dinesh"
  github: "github.com/raghavpoonia"
  license: "MIT"
  created: "2025-01-10"
  estimated_pages: 8
  tags: ["backpropagation", "implementation", "numpy", "gradient-computation", "debugging", "testing"]

# ============================================================================
# SECTION 02_06: BACKPROPAGATION IMPLEMENTATION
# ============================================================================

section_02_06_backprop_implementation:
  
  # --------------------------------------------------------------------------
  # Overview and Context
  # --------------------------------------------------------------------------
  
  overview: |
    Section 02_05 gave you the theory - chain rule, computational graphs,
    mathematical proofs. Now we implement it. Every line of code.
    
    This section builds complete backpropagation from scratch in NumPy:
    layer-wise gradient computation, efficient caching system, gradient
    checking for verification, debugging tools for diagnosis, and comprehensive
    unit tests.
    
    By the end, you'll have a working neural network with verified backprop,
    trained on real data (MNIST), achieving 98%+ accuracy. You'll understand
    every gradient computation intimately because you wrote it yourself.
    
    No PyTorch, no TensorFlow, no autograd libraries. Pure NumPy. This is how
    you build genuine understanding that can't be shaken.
  
  learning_objectives:
    
    conceptual:
      - "Translate mathematical derivations to working code"
      - "Understand caching patterns for efficiency"
      - "Know how to structure backprop for modularity"
      - "Recognize common implementation bugs"
      - "Connect code structure to gradient flow"
    
    practical:
      - "Implement complete backprop system (NumPy only)"
      - "Build layer-wise gradient computation"
      - "Create efficient caching mechanism"
      - "Implement gradient checking suite"
      - "Build debugging and visualization tools"
      - "Train network to convergence on MNIST"
    
    security_focused:
      - "Understand where gradients can be intercepted"
      - "Recognize implementation vulnerabilities"
      - "Know how to audit gradient computations"
      - "Identify potential gradient leakage points"
  
  prerequisites:
    - "Section 02_05 completed (backprop theory)"
    - "Strong NumPy proficiency"
    - "Understanding of object-oriented programming"
  
  # --------------------------------------------------------------------------
  # Topic 1: Layer-Wise Gradient Computation
  # --------------------------------------------------------------------------
  
  layer_wise_gradients:
    
    linear_layer:
      
      forward_pass:
        description: "Linear transformation z = Wx + b"
        
        implementation: |
          class LinearLayer:
              def __init__(self, input_dim, output_dim):
                  """
                  Initialize layer with He initialization for ReLU networks.
                  
                  Parameters:
                  - input_dim: number of input features
                  - output_dim: number of output neurons
                  """
                  # He initialization: good for ReLU activations
                  self.W = np.random.randn(output_dim, input_dim) * np.sqrt(2.0 / input_dim)
                  self.b = np.zeros((output_dim, 1))
                  
                  # Will store gradients here
                  self.dL_dW = None
                  self.dL_db = None
                  
                  # Cache for backward pass
                  self.x = None
                  self.z = None
              
              def forward(self, x):
                  """
                  Forward pass: compute z = Wx + b
                  
                  Parameters:
                  - x: (input_dim, batch_size) input activations
                  
                  Returns:
                  - z: (output_dim, batch_size) linear outputs
                  """
                  self.x = x  # Cache input for backward pass
                  self.z = self.W @ x + self.b
                  return self.z
        
        dimensions: |
          Input shapes:
          - W: (output_dim, input_dim)
          - x: (input_dim, batch_size)
          - b: (output_dim, 1)
          
          Output shape:
          - z: (output_dim, batch_size)
          
          Broadcasting:
          W @ x produces (output_dim, batch_size)
          b broadcasts to each column: (output_dim, 1) → (output_dim, batch_size)
      
      backward_pass:
        description: "Compute gradients wrt weights, bias, and input"
        
        mathematical_formulas: |
          Given: ∂L/∂z (gradient from next layer)
          
          Compute:
          1. ∂L/∂W = (∂L/∂z @ x^T) / batch_size
          2. ∂L/∂b = mean(∂L/∂z, axis=1)
          3. ∂L/∂x = W^T @ ∂L/∂z
        
        implementation: |
          def backward(self, dL_dz):
              """
              Backward pass: compute all gradients
              
              Parameters:
              - dL_dz: (output_dim, batch_size) gradient from next layer
              
              Returns:
              - dL_dx: (input_dim, batch_size) gradient to previous layer
              """
              batch_size = self.x.shape[1]
              
              # Gradient wrt weights: ∂L/∂W = (∂L/∂z @ x^T) / batch_size
              self.dL_dW = (dL_dz @ self.x.T) / batch_size
              
              # Gradient wrt bias: ∂L/∂b = mean of ∂L/∂z across batch
              # Shape: (output_dim, batch_size) → (output_dim, 1)
              self.dL_db = np.mean(dL_dz, axis=1, keepdims=True)
              
              # Gradient to previous layer: ∂L/∂x = W^T @ ∂L/∂z
              dL_dx = self.W.T @ dL_dz
              
              return dL_dx
        
        dimension_analysis: |
          ∂L/∂z shape: (output_dim, batch_size)
          x^T shape: (batch_size, input_dim)
          
          ∂L/∂W = ∂L/∂z @ x^T
                = (output_dim, batch_size) @ (batch_size, input_dim)
                = (output_dim, input_dim) ✓ matches W shape
          
          ∂L/∂b = mean(∂L/∂z, axis=1, keepdims=True)
                = mean over batch → (output_dim, 1) ✓ matches b shape
          
          ∂L/∂x = W^T @ ∂L/∂z
                = (input_dim, output_dim) @ (output_dim, batch_size)
                = (input_dim, batch_size) ✓ matches x shape
      
      parameter_accessors:
        implementation: |
          def get_params(self):
              """Return parameters as dictionary"""
              return {'W': self.W, 'b': self.b}
          
          def get_gradients(self):
              """Return gradients as dictionary"""
              return {'W': self.dL_dW, 'b': self.dL_db}
          
          def update_params(self, learning_rate):
              """Update parameters using computed gradients"""
              self.W -= learning_rate * self.dL_dW
              self.b -= learning_rate * self.dL_db
      
      complete_class: |
        class LinearLayer:
            """Complete linear layer implementation"""
            
            def __init__(self, input_dim, output_dim):
                self.W = np.random.randn(output_dim, input_dim) * np.sqrt(2.0 / input_dim)
                self.b = np.zeros((output_dim, 1))
                self.dL_dW = None
                self.dL_db = None
                self.x = None
                self.z = None
            
            def forward(self, x):
                self.x = x
                self.z = self.W @ x + self.b
                return self.z
            
            def backward(self, dL_dz):
                batch_size = self.x.shape[1]
                self.dL_dW = (dL_dz @ self.x.T) / batch_size
                self.dL_db = np.mean(dL_dz, axis=1, keepdims=True)
                dL_dx = self.W.T @ dL_dz
                return dL_dx
            
            def get_params(self):
                return {'W': self.W, 'b': self.b}
            
            def get_gradients(self):
                return {'W': self.dL_dW, 'b': self.dL_db}
            
            def update_params(self, learning_rate):
                self.W -= learning_rate * self.dL_dW
                self.b -= learning_rate * self.dL_db
    
    activation_layers:
      
      relu_layer:
        forward_pass: |
          class ReLULayer:
              """Rectified Linear Unit activation"""
              
              def __init__(self):
                  self.z = None
                  self.a = None
              
              def forward(self, z):
                  """
                  Apply ReLU: a = max(0, z)
                  
                  Parameters:
                  - z: (n, batch_size) pre-activation values
                  
                  Returns:
                  - a: (n, batch_size) post-activation values
                  """
                  self.z = z  # Cache for backward
                  self.a = np.maximum(0, z)
                  return self.a
        
        backward_pass: |
          def backward(self, dL_da):
              """
              Backward through ReLU
              
              Derivative: f'(z) = 1 if z > 0, else 0
              
              Parameters:
              - dL_da: (n, batch_size) gradient from next layer
              
              Returns:
              - dL_dz: (n, batch_size) gradient to previous layer
              """
              # Element-wise multiplication with ReLU derivative
              # (z > 0) creates boolean mask, converts to 0/1
              dL_dz = dL_da * (self.z > 0)
              return dL_dz
        
        implementation_note: |
          ReLU derivative is simple:
          - If z > 0: gradient flows through (multiply by 1)
          - If z ≤ 0: gradient blocked (multiply by 0)
          
          This creates "dead neurons" when z ≤ 0 for all samples.
        
        complete_class: |
          class ReLULayer:
              def __init__(self):
                  self.z = None
                  self.a = None
              
              def forward(self, z):
                  self.z = z
                  self.a = np.maximum(0, z)
                  return self.a
              
              def backward(self, dL_da):
                  dL_dz = dL_da * (self.z > 0)
                  return dL_dz
      
      sigmoid_layer:
        forward_pass: |
          class SigmoidLayer:
              """Sigmoid activation: σ(z) = 1 / (1 + e^(-z))"""
              
              def __init__(self):
                  self.z = None
                  self.a = None
              
              def forward(self, z):
                  """
                  Apply sigmoid activation
                  
                  Parameters:
                  - z: (n, batch_size) pre-activation
                  
                  Returns:
                  - a: (n, batch_size) values in [0, 1]
                  """
                  self.z = z
                  # Numerical stability: clip z to avoid overflow
                  z_clipped = np.clip(z, -500, 500)
                  self.a = 1 / (1 + np.exp(-z_clipped))
                  return self.a
        
        backward_pass: |
          def backward(self, dL_da):
              """
              Backward through sigmoid
              
              Derivative: σ'(z) = σ(z) * (1 - σ(z))
              
              Parameters:
              - dL_da: (n, batch_size) gradient from next layer
              
              Returns:
              - dL_dz: (n, batch_size)
              """
              # Use cached activation (already computed sigmoid)
              sigmoid = self.a
              dL_dz = dL_da * sigmoid * (1 - sigmoid)
              return dL_dz
        
        complete_class: |
          class SigmoidLayer:
              def __init__(self):
                  self.z = None
                  self.a = None
              
              def forward(self, z):
                  self.z = z
                  z_clipped = np.clip(z, -500, 500)
                  self.a = 1 / (1 + np.exp(-z_clipped))
                  return self.a
              
              def backward(self, dL_da):
                  sigmoid = self.a
                  dL_dz = dL_da * sigmoid * (1 - sigmoid)
                  return dL_dz
      
      tanh_layer:
        forward_pass: |
          class TanhLayer:
              """Hyperbolic tangent activation"""
              
              def forward(self, z):
                  self.z = z
                  self.a = np.tanh(z)
                  return self.a
        
        backward_pass: |
          def backward(self, dL_da):
              """
              Derivative: tanh'(z) = 1 - tanh²(z)
              """
              tanh_z = self.a
              dL_dz = dL_da * (1 - tanh_z ** 2)
              return dL_dz
      
      softmax_crossentropy_combined:
        description: |
          Combining softmax with cross-entropy is more efficient and
          numerically stable than computing them separately.
          
          The gradient simplifies beautifully to: y_pred - y_true
        
        forward_pass: |
          class SoftmaxCrossEntropyLayer:
              """
              Combined softmax + cross-entropy for efficiency.
              
              Softmax: converts logits to probabilities
              Cross-entropy: computes loss
              """
              
              def __init__(self):
                  self.z = None
                  self.y_true = None
                  self.y_pred = None
              
              def forward(self, z, y_true):
                  """
                  Parameters:
                  - z: (n_classes, batch_size) logits
                  - y_true: (n_classes, batch_size) one-hot labels
                  
                  Returns:
                  - loss: scalar
                  - y_pred: (n_classes, batch_size) probabilities
                  """
                  self.z = z
                  self.y_true = y_true
                  
                  # Softmax with numerical stability
                  z_shifted = z - np.max(z, axis=0, keepdims=True)
                  exp_z = np.exp(z_shifted)
                  self.y_pred = exp_z / np.sum(exp_z, axis=0, keepdims=True)
                  
                  # Cross-entropy loss
                  epsilon = 1e-15
                  y_pred_clipped = np.clip(self.y_pred, epsilon, 1 - epsilon)
                  loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=0))
                  
                  return loss, self.y_pred
        
        backward_pass: |
          def backward(self):
              """
              Backward through combined softmax + cross-entropy
              
              Beautiful result: ∂L/∂z = (y_pred - y_true) / batch_size
              
              Returns:
              - dL_dz: (n_classes, batch_size)
              """
              batch_size = self.y_pred.shape[1]
              dL_dz = (self.y_pred - self.y_true) / batch_size
              return dL_dz
        
        why_combined_is_better: |
          Separate computation:
          1. Softmax: ŷ = exp(z) / Σexp(z)
          2. Cross-entropy: L = -Σ y log(ŷ)
          3. Backward through both (complex Jacobian)
          
          Combined:
          ∂L/∂z = ŷ - y (simple subtraction!)
          
          Benefits:
          - Fewer operations
          - More numerically stable
          - Easier to implement correctly
        
        complete_class: |
          class SoftmaxCrossEntropyLayer:
              def __init__(self):
                  self.z = None
                  self.y_true = None
                  self.y_pred = None
              
              def forward(self, z, y_true):
                  self.z = z
                  self.y_true = y_true
                  z_shifted = z - np.max(z, axis=0, keepdims=True)
                  exp_z = np.exp(z_shifted)
                  self.y_pred = exp_z / np.sum(exp_z, axis=0, keepdims=True)
                  epsilon = 1e-15
                  y_pred_clipped = np.clip(self.y_pred, epsilon, 1 - epsilon)
                  loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=0))
                  return loss, self.y_pred
              
              def backward(self):
                  batch_size = self.y_pred.shape[1]
                  dL_dz = (self.y_pred - self.y_true) / batch_size
                  return dL_dz
  
  # --------------------------------------------------------------------------
  # Topic 2: Complete Network Implementation
  # --------------------------------------------------------------------------
  
  complete_network:
    
    network_architecture:
      description: |
        Modular neural network that chains layers together.
        Architecture: Input → [Linear → ReLU] × (L-1) → Linear → Softmax
      
      design_decisions:
        modularity: "Each layer is self-contained (forward, backward, caching)"
        flexibility: "Support arbitrary depth and layer sizes"
        efficiency: "Cache forward values for backward pass"
        simplicity: "ReLU for hidden layers, softmax for output"
    
    network_class:
      initialization: |
        class NeuralNetwork:
            """
            Modular neural network with arbitrary architecture.
            
            Example: NeuralNetwork([784, 128, 64, 10])
            Creates: 784 → 128 → 64 → 10 network
            """
            
            def __init__(self, layer_dims):
                """
                Parameters:
                - layer_dims: list of layer sizes [input, hidden1, ..., output]
                """
                self.layer_dims = layer_dims
                self.num_layers = len(layer_dims) - 1
                
                # Initialize linear layers
                self.linear_layers = []
                for l in range(self.num_layers):
                    linear = LinearLayer(layer_dims[l], layer_dims[l+1])
                    self.linear_layers.append(linear)
                
                # Initialize activation layers (ReLU for hidden layers)
                self.activation_layers = []
                for l in range(self.num_layers - 1):  # No activation after last layer
                    activation = ReLULayer()
                    self.activation_layers.append(activation)
                
                # Output layer (softmax + cross-entropy)
                self.output_layer = SoftmaxCrossEntropyLayer()
      
      forward_pass: |
        def forward(self, x, y_true=None):
            """
            Forward pass through network
            
            Parameters:
            - x: (input_dim, batch_size) input data
            - y_true: (output_dim, batch_size) labels (optional)
            
            Returns:
            - If y_true provided: (loss, predictions)
            - Otherwise: predictions only
            """
            a = x
            
            # Pass through all layers
            for l in range(self.num_layers):
                # Linear transformation
                z = self.linear_layers[l].forward(a)
                
                # Activation (except last layer)
                if l < self.num_layers - 1:
                    a = self.activation_layers[l].forward(z)
                else:
                    # Last layer: keep as logits
                    logits = z
            
            # Output layer
            if y_true is not None:
                # Training: compute loss
                loss, predictions = self.output_layer.forward(logits, y_true)
                return loss, predictions
            else:
                # Inference: just softmax
                z_shifted = logits - np.max(logits, axis=0, keepdims=True)
                exp_z = np.exp(z_shifted)
                predictions = exp_z / np.sum(exp_z, axis=0, keepdims=True)
                return predictions
      
      backward_pass: |
        def backward(self):
            """
            Backward pass: compute gradients for all parameters
            
            Must be called after forward pass with labels.
            """
            # Start from output layer
            dL_dz = self.output_layer.backward()
            
            # Backpropagate through layers (reverse order)
            for l in range(self.num_layers - 1, -1, -1):
                # Backward through linear layer
                dL_da_prev = self.linear_layers[l].backward(dL_dz)
                
                # Backward through activation (if not first layer)
                if l > 0:
                    dL_dz = self.activation_layers[l-1].backward(dL_da_prev)
                # Note: dL_da_prev becomes dL_dz for previous linear layer
      
      parameter_management: |
        def get_parameters(self):
            """Get all parameters as dictionary"""
            params = {}
            for l, layer in enumerate(self.linear_layers):
                layer_params = layer.get_params()
                params[f'W{l+1}'] = layer_params['W']
                params[f'b{l+1}'] = layer_params['b']
            return params
        
        def get_gradients(self):
            """Get all gradients as dictionary"""
            grads = {}
            for l, layer in enumerate(self.linear_layers):
                layer_grads = layer.get_gradients()
                grads[f'W{l+1}'] = layer_grads['W']
                grads[f'b{l+1}'] = layer_grads['b']
            return grads
        
        def update_parameters(self, learning_rate):
            """Update all parameters using gradients"""
            for layer in self.linear_layers:
                layer.update_params(learning_rate)
      
      training_step: |
        def train_step(self, x, y, learning_rate=0.01):
            """
            Single training step: forward, backward, update
            
            Parameters:
            - x: (input_dim, batch_size) input data
            - y: (output_dim, batch_size) labels
            - learning_rate: step size for parameter updates
            
            Returns:
            - loss: scalar loss value
            """
            # Forward pass
            loss, predictions = self.forward(x, y)
            
            # Backward pass
            self.backward()
            
            # Update parameters
            self.update_parameters(learning_rate)
            
            return loss
      
      inference: |
        def predict(self, x):
            """
            Make predictions (inference mode)
            
            Parameters:
            - x: (input_dim, batch_size) input data
            
            Returns:
            - predictions: (output_dim, batch_size) probabilities
            - pred_classes: (batch_size,) predicted class indices
            """
            predictions = self.forward(x)
            pred_classes = np.argmax(predictions, axis=0)
            return predictions, pred_classes
  
  # --------------------------------------------------------------------------
  # Topic 3: Gradient Checking Implementation
  # --------------------------------------------------------------------------
  
  gradient_checking:
    
    why_gradient_checking:
      importance: |
        Backpropagation is easy to implement incorrectly:
        - Wrong matrix transpose
        - Forgot to divide by batch size
        - Sign error
        - Incorrect activation derivative
        
        Gradient checking catches these bugs by comparing analytical gradients
        (from backprop) with numerical gradients (finite differences).
      
      when_to_use:
        - "Before training: verify implementation correct"
        - "After changing architecture: ensure still works"
        - "When debugging convergence issues"
        - "NOT during training: too slow"
    
    numerical_gradient_computation:
      two_sided_difference: |
        For parameter θ and loss function L(θ):
        
        ∂L/∂θ ≈ [L(θ + ε) - L(θ - ε)] / (2ε)
        
        Where ε is small (typically 1e-7)
      
      why_two_sided: |
        One-sided: [L(θ + ε) - L(θ)] / ε has O(ε) error
        Two-sided: [L(θ + ε) - L(θ - ε)] / (2ε) has O(ε²) error
        
        Two-sided is much more accurate!
      
      implementation: |
        def compute_numerical_gradient(network, x, y, param_name, epsilon=1e-7):
            """
            Compute numerical gradient for single parameter.
            
            Parameters:
            - network: neural network
            - x, y: input and labels
            - param_name: e.g., 'W1', 'b2'
            - epsilon: perturbation size
            
            Returns:
            - grad_numerical: same shape as parameter
            """
            # Get original parameter
            params = network.get_parameters()
            param = params[param_name]
            
            # Initialize gradient array
            grad_numerical = np.zeros_like(param)
            
            # Iterate over each element
            it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])
            
            while not it.finished:
                idx = it.multi_index
                original_value = param[idx]
                
                # Compute f(x + epsilon)
                param[idx] = original_value + epsilon
                loss_plus, _ = network.forward(x, y)
                
                # Compute f(x - epsilon)
                param[idx] = original_value - epsilon
                loss_minus, _ = network.forward(x, y)
                
                # Numerical gradient
                grad_numerical[idx] = (loss_plus - loss_minus) / (2 * epsilon)
                
                # Restore original value
                param[idx] = original_value
                
                it.iternext()
            
            return grad_numerical
      
      choosing_epsilon: |
        Too large (ε = 0.1):
        - Poor approximation of derivative
        - Doesn't capture local behavior
        
        Too small (ε = 1e-10):
        - Numerical precision issues
        - Floating point errors dominate
        
        Good choice (ε = 1e-7 or 1e-5):
        - Balance accuracy and precision
        - Standard in practice
    
    gradient_comparison:
      relative_error: |
        Compare analytical vs numerical gradients using relative error:
        
        relative_error = ||g_analytical - g_numerical|| / 
                        (||g_analytical|| + ||g_numerical||)
        
        Where || || is L2 norm (Euclidean norm)
      
      interpretation: |
        relative_error < 1e-7: Perfect! Implementation correct.
        relative_error < 1e-5: Good, acceptable.
        relative_error < 1e-3: Suspicious, investigate.
        relative_error > 1e-3: Bug! Implementation wrong.
      
      implementation: |
        def check_gradients(network, x, y, epsilon=1e-7, threshold=1e-5):
            """
            Verify backprop gradients against numerical gradients.
            
            Parameters:
            - network: neural network
            - x, y: small batch for testing
            - epsilon: finite difference step
            - threshold: acceptable relative error
            
            Returns:
            - results: dict with results for each parameter
            """
            # Forward and backward pass
            loss, _ = network.forward(x, y)
            network.backward()
            
            # Get analytical gradients
            analytical_grads = network.get_gradients()
            
            # Compare each parameter
            results = {}
            print("\nGradient Checking:")
            print("-" * 60)
            
            for param_name in sorted(analytical_grads.keys()):
                print(f"\nChecking {param_name}...")
                
                # Compute numerical gradient
                grad_numerical = compute_numerical_gradient(
                    network, x, y, param_name, epsilon
                )
                
                # Get analytical gradient
                grad_analytical = analytical_grads[param_name]
                
                # Compute relative error
                numerator = np.linalg.norm(grad_analytical - grad_numerical)
                denominator = (np.linalg.norm(grad_analytical) + 
                              np.linalg.norm(grad_numerical))
                relative_error = numerator / (denominator + 1e-10)
                
                # Determine status
                if relative_error < threshold:
                    status = "✓ PASS"
                    symbol = "✓"
                elif relative_error < 1e-3:
                    status = "~ ACCEPTABLE"
                    symbol = "~"
                else:
                    status = "✗ FAIL"
                    symbol = "✗"
                
                print(f"  Relative error: {relative_error:.2e}")
                print(f"  Status: {symbol} {status}")
                
                # Store results
                results[param_name] = {
                    'relative_error': relative_error,
                    'status': status,
                    'analytical': grad_analytical,
                    'numerical': grad_numerical
                }
            
            print("-" * 60)
            return results
      
      usage_example: |
        # Create small network
        network = NeuralNetwork([10, 5, 3])
        
        # Small batch for faster checking
        x = np.random.randn(10, 2)
        y = np.zeros((3, 2))
        y[0, 0] = 1  # Sample 1: class 0
        y[1, 1] = 1  # Sample 2: class 1
        
        # Check gradients
        results = check_gradients(network, x, y)
        
        # Example output:
        # Gradient Checking:
        # ------------------------------------------------------------
        # 
        # Checking W1...
        #   Relative error: 3.24e-08
        #   Status: ✓ PASS
        # 
        # Checking b1...
        #   Relative error: 1.15e-07
        #   Status: ✓ PASS
        # 
        # Checking W2...
        #   Relative error: 5.67e-08
        #   Status: ✓ PASS
        # 
        # Checking b2...
        #   Relative error: 2.41e-07
        #   Status: ✓ PASS
        # ------------------------------------------------------------
    
    debugging_failed_checks:
      common_causes: |
        If gradient check fails, common bugs:
        
        1. Wrong matrix transpose
           - Used W instead of W.T (or vice versa)
           - Check: ∂L/∂x = W^T @ ∂L/∂z
        
        2. Forgot batch size division
           - Used dL_dz @ x.T instead of (dL_dz @ x.T) / batch_size
           - Check: gradient should be average over batch
        
        3. Wrong activation derivative
           - ReLU: should be (z > 0), not (a > 0)
           - Sigmoid: σ(z)(1-σ(z)), not just σ(z)
        
        4. Cache wrong values
           - Used current a instead of cached z in activation backward
           - Check: activation backward needs pre-activation z
        
        5. Sign error
           - Used + instead of - (or vice versa)
           - Check: gradient descent is θ - α·∇L, not θ + α·∇L
      
      debugging_workflow: |
        1. Check simplest layer first (bias usually easiest)
        2. If W correct but b wrong: likely batch size issue
        3. If both wrong: likely transpose or cache issue
        4. Print shapes at each step to verify dimensions
        5. Test on tiny network (2x2 weights) and manually verify
  
  # --------------------------------------------------------------------------
  # Topic 4: Debugging Tools
  # --------------------------------------------------------------------------
  
  debugging_tools:
    
    gradient_monitoring:
      track_norms: |
        def monitor_gradients(network):
            """
            Track gradient statistics to detect issues.
            """
            grads = network.get_gradients()
            
            print("\nGradient Statistics:")
            print("-" * 60)
            
            for param_name in sorted(grads.keys()):
                grad = grads[param_name]
                
                norm = np.linalg.norm(grad)
                mean = np.mean(np.abs(grad))
                max_val = np.max(np.abs(grad))
                min_val = np.min(np.abs(grad))
                
                print(f"\n{param_name}:")
                print(f"  L2 Norm: {norm:.6f}")
                print(f"  Mean |grad|: {mean:.6f}")
                print(f"  Max |grad|: {max_val:.6f}")
                print(f"  Min |grad|: {min_val:.6f}")
            
            print("-" * 60)
      
      detect_vanishing_exploding: |
        def check_gradient_health(network, threshold_vanish=1e-7, 
                                  threshold_explode=100):
            """
            Detect vanishing or exploding gradients.
            
            Returns list of issues found.
            """
            grads = network.get_gradients()
            issues = []
            
            for param_name, grad in grads.items():
                norm = np.linalg.norm(grad)
                
                if norm < threshold_vanish:
                    issues.append(f"VANISHING: {param_name} (norm={norm:.2e})")
                elif norm > threshold_explode:
                    issues.append(f"EXPLODING: {param_name} (norm={norm:.2e})")
            
            if issues:
                print("\n⚠️  Gradient Issues Detected:")
                for issue in issues:
                    print(f"  {issue}")
            else:
                print("\n✓ Gradients healthy")
            
            return issues
      
      gradient_flow_visualization: |
        def visualize_gradient_flow(network, layer_names=None):
            """
            Plot gradient norms per layer to see flow.
            """
            import matplotlib.pyplot as plt
            
            grads = network.get_gradients()
            
            # Extract weight gradients (not bias)
            weight_grads = {k: v for k, v in grads.items() if k.startswith('W')}
            
            layers = sorted(weight_grads.keys())
            norms = [np.linalg.norm(weight_grads[l]) for l in layers]
            
            plt.figure(figsize=(10, 6))
            plt.bar(range(len(layers)), norms)
            plt.xlabel('Layer')
            plt.ylabel('Gradient Norm')
            plt.title('Gradient Flow Through Network')
            plt.xticks(range(len(layers)), layers)
            plt.grid(axis='y', alpha=0.3)
            plt.show()
    
    activation_analysis:
      track_activations: |
        def analyze_activations(network, x):
            """
            Analyze activation statistics per layer.
            """
            print("\nActivation Analysis:")
            print("-" * 60)
            
            a = x
            print(f"\nInput:")
            print(f"  Mean: {np.mean(a):.4f}")
            print(f"  Std: {np.std(a):.4f}")
            print(f"  Min: {np.min(a):.4f}")
            print(f"  Max: {np.max(a):.4f}")
            
            for l in range(network.num_layers):
                # Linear layer
                z = network.linear_layers[l].forward(a)
                
                print(f"\nLayer {l+1} (after linear, before activation):")
                print(f"  Mean: {np.mean(z):.4f}")
                print(f"  Std: {np.std(z):.4f}")
                print(f"  Min: {np.min(z):.4f}")
                print(f"  Max: {np.max(z):.4f}")
                
                # Activation layer (if not last)
                if l < network.num_layers - 1:
                    a = network.activation_layers[l].forward(z)
                    
                    # For ReLU: check dead neurons
                    dead_ratio = np.mean(a == 0, axis=1)
                    avg_dead = np.mean(dead_ratio)
                    
                    print(f"  After ReLU:")
                    print(f"    Mean: {np.mean(a):.4f}")
                    print(f"    Std: {np.std(a):.4f}")
                    print(f"    Dead neurons: {avg_dead*100:.1f}%")
            
            print("-" * 60)
      
      dead_neuron_detector: |
        def detect_dead_neurons(network, dataloader, threshold=0.01):
            """
            Detect neurons that rarely activate across dataset.
            
            Parameters:
            - network: neural network
            - dataloader: iterator yielding (x_batch, y_batch)
            - threshold: activation rate below this = dead
            
            Returns:
            - dead_counts: dict mapping layer to dead neuron count
            """
            activation_counts = {}
            total_samples = 0
            
            for x_batch, _ in dataloader:
                batch_size = x_batch.shape[1]
                total_samples += batch_size
                
                # Forward pass
                a = x_batch
                for l in range(network.num_layers - 1):
                    z = network.linear_layers[l].forward(a)
                    a = network.activation_layers[l].forward(z)
                    
                    # Count activations
                    if l not in activation_counts:
                        activation_counts[l] = np.zeros(a.shape[0])
                    
                    activation_counts[l] += np.sum(a > 0, axis=1)
            
            # Analyze
            print("\nDead Neuron Analysis:")
            print("-" * 60)
            
            dead_counts = {}
            for l in sorted(activation_counts.keys()):
                rates = activation_counts[l] / total_samples
                dead = rates < threshold
                dead_count = np.sum(dead)
                total_neurons = len(dead)
                
                dead_counts[l] = dead_count
                
                print(f"Layer {l+1}:")
                print(f"  Dead: {dead_count}/{total_neurons} ({np.mean(dead)*100:.1f}%)")
                
                if dead_count > 0:
                    print(f"  Dead neuron indices: {np.where(dead)[0][:10]}")  # Show first 10
            
            print("-" * 60)
            return dead_counts
    
    parameter_analysis:
      weight_distribution: |
        def analyze_weight_distributions(network):
            """
            Analyze weight statistics to detect initialization issues.
            """
            params = network.get_parameters()
            
            print("\nWeight Distribution Analysis:")
            print("-" * 60)
            
            for param_name in sorted(params.keys()):
                param = params[param_name]
                
                print(f"\n{param_name}:")
                print(f"  Shape: {param.shape}")
                print(f"  Mean: {np.mean(param):.6f}")
                print(f"  Std: {np.std(param):.6f}")
                print(f"  Min: {np.min(param):.6f}")
                print(f"  Max: {np.max(param):.6f}")
                
                # Check for common issues
                if np.std(param) < 1e-6:
                    print(f"  ⚠️  WARNING: Near-zero variance (poor initialization)")
                if np.max(np.abs(param)) > 10:
                    print(f"  ⚠️  WARNING: Large values (may cause instability)")
            
            print("-" * 60)
  
  # --------------------------------------------------------------------------
  # Topic 5: Training on MNIST
  # --------------------------------------------------------------------------
  
  mnist_training:
    
    data_loading:
      load_data: |
        def load_mnist():
            """
            Load MNIST dataset using sklearn.
            
            Returns:
            - X_train: (60000, 784) training images
            - y_train: (60000,) training labels
            - X_test: (10000, 784) test images
            - y_test: (10000,) test labels
            """
            from sklearn.datasets import fetch_openml
            
            # Load data
            print("Loading MNIST dataset...")
            mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)
            
            X = mnist.data.astype('float32')
            y = mnist.target.astype('int')
            
            # Normalize to [0, 1]
            X /= 255.0
            
            # Split train/test
            X_train, X_test = X[:60000], X[60000:]
            y_train, y_test = y[:60000], y[60000:]
            
            print(f"Loaded: {X_train.shape[0]} train, {X_test.shape[0]} test samples")
            
            return X_train, y_train, X_test, y_test
      
      preprocess: |
        def preprocess_mnist(X, y):
            """
            Prepare data for neural network.
            
            Parameters:
            - X: (n_samples, 784) images
            - y: (n_samples,) integer labels
            
            Returns:
            - X: (784, n_samples) transposed
            - y_onehot: (10, n_samples) one-hot encoded
            """
            # Transpose X to match our convention (features, samples)
            X = X.T
            
            # One-hot encode labels
            n_samples = y.shape[0]
            n_classes = 10
            y_onehot = np.zeros((n_classes, n_samples))
            y_onehot[y, np.arange(n_samples)] = 1
            
            return X, y_onehot
      
      create_dataloader: |
        def create_dataloader(X, y, batch_size, shuffle=True):
            """
            Create simple dataloader (iterator over batches).
            
            Yields: (X_batch, y_batch) tuples
            """
            n_samples = X.shape[1]
            n_batches = (n_samples + batch_size - 1) // batch_size
            
            if shuffle:
                indices = np.random.permutation(n_samples)
                X = X[:, indices]
                y = y[:, indices]
            
            for batch in range(n_batches):
                start = batch * batch_size
                end = min(start + batch_size, n_samples)
                yield X[:, start:end], y[:, start:end]
    
    training_loop:
      train_function: |
        def train(network, X_train, y_train, X_val, y_val,
                  batch_size=32, epochs=10, learning_rate=0.01):
            """
            Train neural network on MNIST.
            
            Parameters:
            - network: NeuralNetwork instance
            - X_train, y_train: training data
            - X_val, y_val: validation data
            - batch_size: samples per batch
            - epochs: number of full passes through data
            - learning_rate: step size for parameter updates
            
            Returns:
            - history: dict with training/validation metrics
            """
            n_samples = X_train.shape[1]
            n_batches = n_samples // batch_size
            
            history = {
                'train_loss': [],
                'val_loss': [],
                'val_accuracy': []
            }
            
            print(f"\nTraining on {n_samples} samples, batch_size={batch_size}")
            print(f"Architecture: {network.layer_dims}")
            print("-" * 60)
            
            for epoch in range(epochs):
                # Shuffle training data
                indices = np.random.permutation(n_samples)
                X_shuffled = X_train[:, indices]
                y_shuffled = y_train[:, indices]
                
                # Training epoch
                epoch_losses = []
                
                for batch in range(n_batches):
                    # Get batch
                    start = batch * batch_size
                    end = start + batch_size
                    X_batch = X_shuffled[:, start:end]
                    y_batch = y_shuffled[:, start:end]
                    
                    # Training step
                    loss = network.train_step(X_batch, y_batch, learning_rate)
                    epoch_losses.append(loss)
                
                # Epoch statistics
                train_loss = np.mean(epoch_losses)
                val_loss, val_acc = evaluate(network, X_val, y_val, batch_size)
                
                history['train_loss'].append(train_loss)
                history['val_loss'].append(val_loss)
                history['val_accuracy'].append(val_acc)
                
                print(f"Epoch {epoch+1:2d}/{epochs}: "
                      f"train_loss={train_loss:.4f}, "
                      f"val_loss={val_loss:.4f}, "
                      f"val_acc={val_acc:.4f}")
            
            print("-" * 60)
            return history
      
      evaluate_function: |
        def evaluate(network, X, y, batch_size=256):
            """
            Evaluate network on dataset.
            
            Parameters:
            - network: NeuralNetwork instance
            - X, y: data to evaluate on
            - batch_size: batch size for evaluation
            
            Returns:
            - avg_loss: average loss
            - accuracy: classification accuracy
            """
            n_samples = X.shape[1]
            n_batches = (n_samples + batch_size - 1) // batch_size
            
            total_loss = 0
            correct = 0
            
            for batch in range(n_batches):
                start = batch * batch_size
                end = min(start + batch_size, n_samples)
                X_batch = X[:, start:end]
                y_batch = y[:, start:end]
                
                # Forward pass
                loss, predictions = network.forward(X_batch, y_batch)
                
                # Accumulate loss
                total_loss += loss * (end - start)
                
                # Compute accuracy
                pred_classes = np.argmax(predictions, axis=0)
                true_classes = np.argmax(y_batch, axis=0)
                correct += np.sum(pred_classes == true_classes)
            
            avg_loss = total_loss / n_samples
            accuracy = correct / n_samples
            
            return avg_loss, accuracy
    
    complete_example:
      full_training_script: |
        # ========================================
        # Complete MNIST Training Script
        # ========================================
        
        import numpy as np
        
        # 1. Load and preprocess data
        print("=" * 60)
        print("Step 1: Loading MNIST")
        print("=" * 60)
        
        X_train, y_train, X_test, y_test = load_mnist()
        
        X_train, y_train = preprocess_mnist(X_train, y_train)
        X_test, y_test = preprocess_mnist(X_test, y_test)
        
        # Split validation set
        X_val = X_train[:, :10000]
        y_val = y_train[:, :10000]
        X_train = X_train[:, 10000:]
        y_train = y_train[:, 10000:]
        
        print(f"\nData shapes:")
        print(f"  Train: {X_train.shape}")
        print(f"  Val: {X_val.shape}")
        print(f"  Test: {X_test.shape}")
        
        # 2. Create network
        print("\n" + "=" * 60)
        print("Step 2: Creating Network")
        print("=" * 60)
        
        network = NeuralNetwork([784, 128, 64, 10])
        
        print(f"\nNetwork architecture:")
        print(f"  Input: 784 (28x28 image)")
        print(f"  Hidden 1: 128 neurons (ReLU)")
        print(f"  Hidden 2: 64 neurons (ReLU)")
        print(f"  Output: 10 classes (Softmax)")
        
        # Count parameters
        params = network.get_parameters()
        total_params = sum(p.size for p in params.values())
        print(f"\nTotal parameters: {total_params:,}")
        
        # 3. Gradient checking on small batch
        print("\n" + "=" * 60)
        print("Step 3: Gradient Checking")
        print("=" * 60)
        
        X_tiny = X_train[:, :2]
        y_tiny = y_train[:, :2]
        
        results = check_gradients(network, X_tiny, y_tiny)
        
        # Verify all passed
        all_passed = all(r['status'].startswith('✓') for r in results.values())
        
        if all_passed:
            print("\n✅ All gradient checks passed! Implementation correct.")
        else:
            print("\n❌ Some gradient checks failed! Fix bugs before training.")
            exit(1)
        
        # 4. Train network
        print("\n" + "=" * 60)
        print("Step 4: Training")
        print("=" * 60)
        
        history = train(
            network, X_train, y_train, X_val, y_val,
            batch_size=32,
            epochs=10,
            learning_rate=0.01
        )
        
        # 5. Final evaluation on test set
        print("\n" + "=" * 60)
        print("Step 5: Test Set Evaluation")
        print("=" * 60)
        
        test_loss, test_acc = evaluate(network, X_test, y_test)
        
        print(f"\nFinal Test Results:")
        print(f"  Loss: {test_loss:.4f}")
        print(f"  Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)")
        
        # 6. Analyze results
        print("\n" + "=" * 60)
        print("Step 6: Analysis")
        print("=" * 60)
        
        # Check for dead neurons
        train_loader = create_dataloader(X_train, y_train, batch_size=256, shuffle=False)
        dead_counts = detect_dead_neurons(network, train_loader)
        
        # Analyze gradients on one batch
        X_batch = X_train[:, :32]
        y_batch = y_train[:, :32]
        _, _ = network.forward(X_batch, y_batch)
        network.backward()
        check_gradient_health(network)
        
        print("\n" + "=" * 60)
        print("Training Complete!")
        print("=" * 60)
      
      expected_results: |
        Expected output (approximate):
        
        Epoch  1/10: train_loss=0.4523, val_loss=0.2891, val_acc=0.9156
        Epoch  2/10: train_loss=0.2134, val_loss=0.1823, val_acc=0.9456
        Epoch  3/10: train_loss=0.1567, val_loss=0.1423, val_acc=0.9587
        Epoch  4/10: train_loss=0.1234, val_loss=0.1189, val_acc=0.9656
        Epoch  5/10: train_loss=0.1012, val_loss=0.1034, val_acc=0.9701
        Epoch  6/10: train_loss=0.0856, val_loss=0.0923, val_acc=0.9734
        Epoch  7/10: train_loss=0.0734, val_loss=0.0856, val_acc=0.9756
        Epoch  8/10: train_loss=0.0645, val_loss=0.0812, val_acc=0.9768
        Epoch  9/10: train_loss=0.0578, val_loss=0.0789, val_acc=0.9779
        Epoch 10/10: train_loss=0.0523, val_loss=0.0776, val_acc=0.9785
        
        Final Test Results:
          Loss: 0.0821
          Accuracy: 0.9742 (97.42%)
        
        This is good performance for a simple 2-hidden-layer network!
  
  # --------------------------------------------------------------------------
  # Key Takeaways
  # --------------------------------------------------------------------------
  
  key_takeaways:
    
    critical_concepts:
      - "Layer-wise implementation: each layer self-contained (forward, backward, cache)"
      - "Forward MUST cache z and a: backward pass needs them, recomputation wasteful"
      - "Gradient formula: ∂L/∂W = (∂L/∂z @ x^T) / batch_size - divide by batch!"
      - "Softmax+CrossEntropy combined: gradient simplifies to y_pred - y_true"
      - "Gradient checking essential: relative error < 1e-5 means correct implementation"
      - "Monitor gradient norms: detect vanishing (<1e-7) or exploding (>100) early"
    
    actionable_steps:
      - "Always gradient check before training: catches 90% of bugs when network small"
      - "Implement layers separately: LinearLayer, ReLULayer modular and testable"
      - "Cache in layer objects: self.x, self.z stored during forward, used in backward"
      - "Use He initialization for ReLU: W * sqrt(2/n_in) prevents gradient issues"
      - "Start tiny: verify correctness on 2-sample batch before scaling to thousands"
      - "Track dead neurons: if >20% dead, switch to Leaky ReLU or reduce learning rate"
    
    security_principles:
      - "Gradients accessible via backward(): adversary who can run this gets all gradients"
      - "Cache contains intermediate activations: information leakage if cache exposed"
      - "Gradient magnitude reveals model state: monitor for anomalies in production"
      - "Implementation bugs create vulnerabilities: incorrect gradients = exploitable weak model"
    
    common_bugs_avoided:
      - "Wrong transpose: W.T @ dL_dz, not W @ dL_dz"
      - "Forgot batch division: gradient/batch_size, not just gradient"
      - "Wrong cache: activation backward needs z (pre-activation), not a (post-activation)"
      - "Dimension mismatch: always verify shapes match expected (use assertions)"
      - "Numerical instability: clip before exp/log to avoid overflow/underflow"

---
