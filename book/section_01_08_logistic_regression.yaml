# section_01_08_logistic_regression.yaml

---
document_info:
  chapter: "01"
  section: "08"
  title: "Logistic Regression from Scratch"
  version: "1.0.0"
  author: "Raghav Dinesh"
  github: "github.com/raghavpoonia"
  license: "MIT"
  created: "2025-12-30"
  estimated_pages: 7
  tags: ["logistic-regression", "sigmoid", "binary-classification", "gradient-descent", "log-loss", "numpy-implementation"]

# ============================================================================
# SECTION 1.08: LOGISTIC REGRESSION FROM SCRATCH
# ============================================================================

section_01_08_logistic_regression:
  
  # --------------------------------------------------------------------------
  # Overview and Context
  # --------------------------------------------------------------------------
  
  overview: |
    Logistic regression is the workhorse of binary classification. Despite its name, 
    it's a classification algorithm, not regression. It's the foundation for understanding 
    neural networks, and it's still used in production at massive scale because it's 
    fast, interpretable, and works surprisingly well.
    
    Every major tech company uses logistic regression somewhere in their stack:
    - Google: Ad click prediction (billions of predictions per day)
    - Facebook: Spam detection, content moderation
    - Netflix: Recommendation systems
    - Security vendors: Malware detection, fraud detection
    
    This section builds logistic regression from absolute scratch using only NumPy. 
    We'll implement the sigmoid function, derive the loss function, compute gradients 
    by hand, and train with gradient descent. By the end, you'll have a working 
    binary classifier that you coded yourself - no scikit-learn, no magic.
    
    Understanding logistic regression at this level is critical because:
    1. It's the building block for neural networks (chain these together = deep learning)
    2. You'll understand why gradient descent works (foundation of all ML)
    3. You can debug model failures (know what's happening under the hood)
    4. You can explain model predictions (important for security)
  
  why_this_matters: |
    Security context:
    - Interpretable: Can explain WHY something was classified as malicious
    - Fast: Sub-millisecond predictions (critical for real-time detection)
    - Scalable: Billions of predictions per day on single machine
    - Probabilistic: Outputs calibrated probabilities for risk assessment
    - Robust: Doesn't overfit easily (good for adversarial environments)
    
    Use cases:
    - Email spam detection (text features → spam probability)
    - Phishing URL detection (domain features → phishing probability)
    - Fraud detection (transaction features → fraud probability)
    - Intrusion detection (packet features → attack probability)
    - Malware detection (file features → malicious probability)
  
  # --------------------------------------------------------------------------
  # Core Concept 1: The Sigmoid Function
  # --------------------------------------------------------------------------
  
  sigmoid_function:
    
    motivation: |
      Problem: We want to predict probabilities (values between 0 and 1)
      But: Linear function y = wx + b can output any value (-∞ to +∞)
      Solution: Sigmoid function "squashes" linear output to [0, 1] range
    
    formula: "σ(z) = 1 / (1 + e^(-z))"
    
    properties:
      range: "[0, 1] - perfect for probabilities"
      
      boundary_values:
        - "σ(0) = 0.5 (neutral point)"
        - "σ(∞) → 1 (very positive input → probability near 1)"
        - "σ(-∞) → 0 (very negative input → probability near 0)"
      
      shape: "S-shaped curve (sigmoid = 'S-shaped')"
      
      derivative: "σ'(z) = σ(z) × (1 - σ(z)) - used in gradient descent!"
    
    geometric_intuition: |
      Think of z = wx + b as "evidence" for positive class:
      - Large positive z: Strong evidence → σ(z) ≈ 1 (high probability)
      - Near zero z: No evidence → σ(z) ≈ 0.5 (uncertain)
      - Large negative z: Strong evidence against → σ(z) ≈ 0 (low probability)
      
      Sigmoid converts evidence to probability smoothly.
    
    numpy_implementation: |
      import numpy as np
      
      def sigmoid(z):
          """
          Sigmoid activation function: σ(z) = 1 / (1 + e^(-z))
          
          Args:
              z: Input (scalar, vector, or matrix)
          
          Returns:
              Output in range [0, 1]
          """
          return 1 / (1 + np.exp(-z))
      
      # Examples
      print(f"σ(0) = {sigmoid(0)}")       # 0.5
      print(f"σ(5) = {sigmoid(5)}")       # 0.993 (very confident)
      print(f"σ(-5) = {sigmoid(-5)}")     # 0.007 (very confident)
      
      # Vectorized operation
      z_values = np.array([-3, -1, 0, 1, 3])
      probabilities = sigmoid(z_values)
      print(f"Probabilities: {probabilities}")
      # [0.047, 0.269, 0.5, 0.731, 0.953]
    
    numerical_stability: |
      Problem: For very negative z (e.g., z = -1000), e^(-z) overflows
      
      Solution: Use numerically stable implementation
      
      def sigmoid_stable(z):
          """Numerically stable sigmoid"""
          # For positive z: use standard formula
          # For negative z: use σ(z) = e^z / (1 + e^z)
          
          pos_mask = (z >= 0)
          neg_mask = (z < 0)
          
          result = np.zeros_like(z, dtype=float)
          
          # Positive z
          result[pos_mask] = 1 / (1 + np.exp(-z[pos_mask]))
          
          # Negative z (alternative form)
          exp_z = np.exp(z[neg_mask])
          result[neg_mask] = exp_z / (1 + exp_z)
          
          return result
  
  # --------------------------------------------------------------------------
  # Core Concept 2: Logistic Regression Model
  # --------------------------------------------------------------------------
  
  logistic_regression_model:
    
    model_equation: |
      Linear combination: z = w·x + b = w₁x₁ + w₂x₂ + ... + wₙxₙ + b
      
      Probability prediction: P(y=1|x) = σ(z) = 1 / (1 + e^(-z))
      
      Where:
      - x: Input features [x₁, x₂, ..., xₙ]
      - w: Weights [w₁, w₂, ..., wₙ] (parameters to learn)
      - b: Bias (intercept, parameter to learn)
      - z: Linear combination (also called "logit")
      - σ(z): Sigmoid function
      - P(y=1|x): Probability that y=1 given input x
    
    vectorized_form: |
      For multiple samples (rows = samples, columns = features):
      
      Z = XW + b
      
      Where:
      - X: (m, n) matrix - m samples, n features
      - W: (n, 1) vector - weights for each feature
      - b: scalar - bias
      - Z: (m, 1) vector - linear outputs for all samples
      
      Predictions: P = σ(Z)
    
    interpretation: |
      Each weight wᵢ represents importance of feature i:
      - Positive weight: Feature increases probability of positive class
      - Negative weight: Feature decreases probability of positive class
      - Weight magnitude: How strongly feature influences prediction
      
      Example (spam detection):
      - w₁ = 0.5 for "exclamation_count": More exclamations → higher spam probability
      - w₂ = -0.3 for "email_length": Longer emails → lower spam probability
      - b = -1.0: Base spam probability (when all features = 0)
    
    decision_boundary: |
      Model predicts class 1 if P(y=1|x) > 0.5
      This happens when z > 0 (since σ(0) = 0.5)
      
      Decision boundary equation: w·x + b = 0
      
      This is a hyperplane (line in 2D, plane in 3D) separating classes
    
    example_2d: |
      Two features: exclamations (x₁) and capitals (x₂)
      Learned weights: w₁=2, w₂=3, b=-10
      
      Decision boundary: 2x₁ + 3x₂ - 10 = 0
      Rearranged: x₂ = (10 - 2x₁) / 3
      
      Email 1: x₁=3, x₂=2
      z = 2(3) + 3(2) - 10 = 6 + 6 - 10 = 2
      P(spam) = σ(2) = 0.88 → Spam
      
      Email 2: x₁=1, x₂=1
      z = 2(1) + 3(1) - 10 = 2 + 3 - 10 = -5
      P(spam) = σ(-5) = 0.007 → Not spam
  
  # --------------------------------------------------------------------------
  # Core Concept 3: Binary Cross-Entropy Loss
  # --------------------------------------------------------------------------
  
  binary_cross_entropy_loss:
    
    why_not_mse: |
      Mean Squared Error (MSE): (ŷ - y)²
      
      Problem with MSE for classification:
      1. Gradient descent gets stuck (non-convex optimization landscape)
      2. Doesn't penalize confident wrong predictions appropriately
      3. Doesn't match probabilistic interpretation
      
      Need loss function that:
      - Is convex (single global minimum, gradient descent works)
      - Heavily penalizes confident wrong predictions
      - Matches maximum likelihood estimation
    
    cross_entropy_formula: |
      For single sample:
      L(y, ŷ) = -[y log(ŷ) + (1-y) log(1-ŷ)]
      
      Where:
      - y: True label (0 or 1)
      - ŷ: Predicted probability (output of sigmoid)
      - L: Loss (higher = worse prediction)
    
    intuition: |
      Case 1: True label y=1 (positive class)
      Loss = -log(ŷ)
      
      - If ŷ=1 (confident and correct): Loss = -log(1) = 0 (perfect)
      - If ŷ=0.5 (uncertain): Loss = -log(0.5) = 0.69 (moderate)
      - If ŷ=0.01 (confident but wrong): Loss = -log(0.01) = 4.6 (very bad!)
      
      Case 2: True label y=0 (negative class)
      Loss = -log(1-ŷ)
      
      - If ŷ=0 (confident and correct): Loss = -log(1) = 0 (perfect)
      - If ŷ=0.5 (uncertain): Loss = -log(0.5) = 0.69 (moderate)
      - If ŷ=0.99 (confident but wrong): Loss = -log(0.01) = 4.6 (very bad!)
      
      Key insight: Loss explodes as model becomes confident AND wrong
    
    average_loss: |
      For m training samples:
      
      J(w, b) = -(1/m) Σᵢ [yᵢ log(ŷᵢ) + (1-yᵢ) log(1-ŷᵢ)]
      
      This is the cost function we minimize during training
    
    numpy_implementation: |
      def binary_cross_entropy(y_true, y_pred):
          """
          Binary cross-entropy loss
          
          Args:
              y_true: True labels (0 or 1), shape (m,)
              y_pred: Predicted probabilities, shape (m,)
          
          Returns:
              Average loss across samples
          """
          m = len(y_true)
          
          # Clip predictions to avoid log(0)
          epsilon = 1e-15
          y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
          
          # Compute loss
          loss = -np.mean(
              y_true * np.log(y_pred) + 
              (1 - y_true) * np.log(1 - y_pred)
          )
          
          return loss
      
      # Example
      y_true = np.array([1, 0, 1, 1, 0])
      y_pred = np.array([0.9, 0.1, 0.8, 0.6, 0.2])
      
      loss = binary_cross_entropy(y_true, y_pred)
      print(f"Loss: {loss:.4f}")  # Lower is better
    
    why_cross_entropy_works: |
      Mathematical connection: Binary cross-entropy is negative log-likelihood
      
      Minimizing cross-entropy = Maximizing likelihood of correct labels
      
      This is the "right" loss for probabilistic classification because it 
      derives from maximum likelihood estimation (MLE) principle.
  
  # --------------------------------------------------------------------------
  # Core Concept 4: Gradient Descent for Logistic Regression
  # --------------------------------------------------------------------------
  
  gradient_descent:
    
    goal: "Find weights w and bias b that minimize loss J(w, b)"
    
    gradient_descent_algorithm: |
      Start with random w, b
      Repeat until convergence:
          1. Compute predictions: ŷ = σ(Xw + b)
          2. Compute loss: J = binary_cross_entropy(y, ŷ)
          3. Compute gradients: dw, db
          4. Update parameters: w = w - α·dw, b = b - α·db
      
      Where α is learning rate (step size)
    
    gradient_formulas: |
      Gradient with respect to weights:
      ∂J/∂w = (1/m) Xᵀ(ŷ - y)
      
      Gradient with respect to bias:
      ∂J/∂b = (1/m) Σ(ŷ - y)
      
      Derivation (using chain rule):
      ∂J/∂w = (∂J/∂ŷ) × (∂ŷ/∂z) × (∂z/∂w)
            = -(y/ŷ - (1-y)/(1-ŷ)) × σ(z)(1-σ(z)) × x
            = (ŷ - y) × x  [after simplification]
    
    update_rule: |
      New weights: w_new = w_old - α × (1/m) Xᵀ(ŷ - y)
      New bias: b_new = b_old - α × (1/m) Σ(ŷ - y)
      
      Intuition:
      - If ŷ > y (predicted too high): gradient positive → decrease w
      - If ŷ < y (predicted too low): gradient negative → increase w
      - Magnitude of update proportional to error (ŷ - y)
    
    learning_rate: |
      α (alpha) controls step size:
      
      Too large:
      - Optimization overshoots minimum
      - Loss oscillates or diverges
      - Training unstable
      
      Too small:
      - Optimization takes forever
      - Might get stuck in plateau
      - Wastes computation
      
      Typical values: 0.001 to 1.0 (depends on feature scaling)
      
      Strategy: Start with 0.01, adjust if loss doesn't decrease
    
    convergence_criteria: |
      Stop training when:
      1. Loss change < threshold (e.g., |J_new - J_old| < 0.0001)
      2. Maximum iterations reached (e.g., 1000 iterations)
      3. Gradient magnitude very small (near minimum)
      
      In practice: Monitor loss, stop when it flattens out
  
  # --------------------------------------------------------------------------
  # Complete Implementation: Logistic Regression from Scratch
  # --------------------------------------------------------------------------
  
  complete_implementation: |
    import numpy as np
    
    class LogisticRegression:
        """
        Binary logistic regression classifier
        Built from scratch using only NumPy
        """
        
        def __init__(self, learning_rate=0.01, n_iterations=1000, verbose=False):
            """
            Initialize logistic regression model
            
            Args:
                learning_rate: Step size for gradient descent
                n_iterations: Number of training iterations
                verbose: Print training progress
            """
            self.learning_rate = learning_rate
            self.n_iterations = n_iterations
            self.verbose = verbose
            
            # Parameters (learned during training)
            self.weights = None
            self.bias = None
            
            # Training history
            self.losses = []
        
        def _sigmoid(self, z):
            """Sigmoid activation function"""
            return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # Clip for stability
        
        def _compute_loss(self, y_true, y_pred):
            """Binary cross-entropy loss"""
            m = len(y_true)
            epsilon = 1e-15
            y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
            
            loss = -np.mean(
                y_true * np.log(y_pred) + 
                (1 - y_true) * np.log(1 - y_pred)
            )
            return loss
        
        def fit(self, X, y):
            """
            Train logistic regression model
            
            Args:
                X: Training features, shape (m_samples, n_features)
                y: Training labels, shape (m_samples,)
            """
            m, n = X.shape
            
            # Initialize parameters
            self.weights = np.zeros(n)
            self.bias = 0
            
            # Gradient descent
            for iteration in range(self.n_iterations):
                # Forward pass: compute predictions
                z = np.dot(X, self.weights) + self.bias
                y_pred = self._sigmoid(z)
                
                # Compute loss
                loss = self._compute_loss(y, y_pred)
                self.losses.append(loss)
                
                # Backward pass: compute gradients
                dz = y_pred - y  # Error
                dw = (1/m) * np.dot(X.T, dz)  # Gradient w.r.t. weights
                db = (1/m) * np.sum(dz)  # Gradient w.r.t. bias
                
                # Update parameters
                self.weights -= self.learning_rate * dw
                self.bias -= self.learning_rate * db
                
                # Print progress
                if self.verbose and iteration % 100 == 0:
                    print(f"Iteration {iteration}: Loss = {loss:.4f}")
            
            return self
        
        def predict_proba(self, X):
            """
            Predict class probabilities
            
            Args:
                X: Features, shape (m_samples, n_features)
            
            Returns:
                Probabilities P(y=1), shape (m_samples,)
            """
            z = np.dot(X, self.weights) + self.bias
            return self._sigmoid(z)
        
        def predict(self, X, threshold=0.5):
            """
            Predict class labels
            
            Args:
                X: Features, shape (m_samples, n_features)
                threshold: Classification threshold (default 0.5)
            
            Returns:
                Predicted labels (0 or 1), shape (m_samples,)
            """
            probabilities = self.predict_proba(X)
            return (probabilities >= threshold).astype(int)
        
        def score(self, X, y):
            """
            Compute accuracy on dataset
            
            Args:
                X: Features
                y: True labels
            
            Returns:
                Accuracy (fraction of correct predictions)
            """
            predictions = self.predict(X)
            return np.mean(predictions == y)
    
    # ========================================================================
    # USAGE EXAMPLE: Spam Detection
    # ========================================================================
    
    # Generate synthetic spam detection dataset
    np.random.seed(42)
    
    # Features: [exclamation_count, capital_count, email_length, contains_money]
    # Spam: Many exclamations, many capitals, contains money
    # Not spam: Few exclamations, few capitals, no money words
    
    # Generate 500 spam emails
    spam_features = np.random.randn(500, 4)
    spam_features[:, 0] += 5  # More exclamations
    spam_features[:, 1] += 4  # More capitals
    spam_features[:, 3] += 3  # Contains money words
    spam_labels = np.ones(500)
    
    # Generate 500 legitimate emails
    legit_features = np.random.randn(500, 4)
    legit_features[:, 0] -= 2  # Fewer exclamations
    legit_features[:, 1] -= 1  # Fewer capitals
    legit_features[:, 3] -= 2  # No money words
    legit_labels = np.zeros(500)
    
    # Combine datasets
    X = np.vstack([spam_features, legit_features])
    y = np.hstack([spam_labels, legit_labels])
    
    # Shuffle
    shuffle_idx = np.random.permutation(len(y))
    X, y = X[shuffle_idx], y[shuffle_idx]
    
    # Split into train/test (80/20)
    split = int(0.8 * len(y))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]
    
    # Train model
    model = LogisticRegression(learning_rate=0.1, n_iterations=1000, verbose=True)
    model.fit(X_train, y_train)
    
    # Evaluate
    train_acc = model.score(X_train, y_train)
    test_acc = model.score(X_test, y_test)
    
    print(f"\nTraining Accuracy: {train_acc:.2%}")
    print(f"Test Accuracy: {test_acc:.2%}")
    
    # Analyze learned weights
    feature_names = ['exclamation_count', 'capital_count', 'email_length', 'contains_money']
    print("\nLearned feature weights:")
    for name, weight in zip(feature_names, model.weights):
        print(f"  {name:20s}: {weight:+.4f}")
    print(f"  {'Bias':20s}: {model.bias:+.4f}")
    
    # Make predictions on new emails
    new_emails = np.array([
        [10, 15, 100, 5],  # Spam-like: many exclamations, capitals, money words
        [1, 2, 200, -1],   # Legit-like: few exclamations, capitals, no money
    ])
    
    probabilities = model.predict_proba(new_emails)
    predictions = model.predict(new_emails)
    
    print("\nNew email predictions:")
    for i, (prob, pred) in enumerate(zip(probabilities, predictions)):
        label = "SPAM" if pred == 1 else "NOT SPAM"
        print(f"  Email {i+1}: {label} (confidence: {prob:.2%})")
  
  # --------------------------------------------------------------------------
  # Advanced Topics
  # --------------------------------------------------------------------------
  
  advanced_topics:
    
    regularization:
      
      problem: "Overfitting - model memorizes training data, fails on new data"
      
      solution: "Add penalty term to loss function"
      
      l2_regularization: |
        Modified loss: J = BCE_loss + λ × ||w||²
        
        Where:
        - λ (lambda): Regularization strength
        - ||w||²: Sum of squared weights
        
        Effect: Penalizes large weights, encourages simpler model
        
        Gradient update:
        w_new = w_old - α × (gradient + 2λw)
      
      l1_regularization: |
        Modified loss: J = BCE_loss + λ × ||w||₁
        
        Where ||w||₁ = |w₁| + |w₂| + ... + |wₙ|
        
        Effect: Drives some weights to exactly zero (feature selection)
    
    mini_batch_gradient_descent:
      
      batch_gradient_descent: |
        Use all training samples to compute gradient
        
        Pros: Smooth convergence, stable
        Cons: Slow for large datasets (millions of samples)
      
      stochastic_gradient_descent: |
        Use one sample at a time to compute gradient
        
        Pros: Fast updates, can escape local minima
        Cons: Noisy gradient, erratic convergence
      
      mini_batch: |
        Use subset of samples (e.g., 32, 64, 128) per iteration
        
        Pros: Balance speed and stability
        Cons: Needs batch size tuning
        
        Most common in practice: Mini-batch with batch size 32-256
    
    multiclass_extension:
      
      softmax_regression: |
        Extension to K classes (K > 2)
        
        Model:
        For each class k: z_k = w_k · x + b_k
        Probabilities: P(y=k|x) = exp(z_k) / Σⱼ exp(z_j)
        
        Loss: Categorical cross-entropy
        L = -Σₖ yₖ log(ŷₖ)
        
        This is multinomial logistic regression (covered in Section 11)
  
  # --------------------------------------------------------------------------
  # Common Mistakes
  # --------------------------------------------------------------------------
  
  common_mistakes:
    
    mistake_1:
      error: "Not scaling features before training"
      
      problem: |
        Features with different scales cause gradient descent issues:
        - Large-scale features dominate gradients
        - Small learning rate needed (slow convergence)
        - Or large learning rate causes oscillation
      
      example: |
        Feature 1: exclamation_count (range 0-10)
        Feature 2: email_length (range 10-10000)
        
        Gradient w.r.t. feature 2 is 1000x larger!
      
      fix: "Standardize features: (X - mean) / std before training"
    
    mistake_2:
      error: "Using 0.5 threshold without considering class imbalance"
      
      problem: |
        Dataset: 99% legitimate, 1% spam
        Model predicts everything as legitimate (P(spam) < 0.5 always)
        Accuracy = 99% but detects zero spam!
      
      fix: |
        Adjust threshold based on:
        - Cost of false positives vs false negatives
        - Base rate of positive class
        - Use ROC curve to find optimal threshold (Section 11)
    
    mistake_3:
      error: "Training for too long (overfitting)"
      
      symptom: |
        Training loss keeps decreasing
        Test loss starts increasing
        Gap between train and test accuracy widens
      
      fix: |
        - Monitor validation loss, stop when it starts increasing
        - Use regularization (L2 penalty)
        - Reduce model complexity
    
    mistake_4:
      error: "Not checking gradient computation"
      
      problem: |
        Gradient descent fails silently if gradients wrong
        Loss doesn't decrease or increases
        Model doesn't learn
      
      fix: |
        Gradient checking: Compare analytical gradient to numerical gradient
        
        def gradient_check(model, X, y, epsilon=1e-7):
            """Verify gradient computation is correct"""
            # Compute analytical gradient
            y_pred = model._sigmoid(np.dot(X, model.weights) + model.bias)
            dw_analytical = (1/len(y)) * np.dot(X.T, y_pred - y)
            
            # Compute numerical gradient (finite differences)
            dw_numerical = np.zeros_like(model.weights)
            for i in range(len(model.weights)):
                w_plus = model.weights.copy()
                w_plus[i] += epsilon
                loss_plus = compute_loss_with_weights(X, y, w_plus, model.bias)
                
                w_minus = model.weights.copy()
                w_minus[i] -= epsilon
                loss_minus = compute_loss_with_weights(X, y, w_minus, model.bias)
                
                dw_numerical[i] = (loss_plus - loss_minus) / (2 * epsilon)
            
            # Compare
            diff = np.linalg.norm(dw_analytical - dw_numerical)
            print(f"Gradient difference: {diff}")
            assert diff < 1e-5, "Gradient computation incorrect!"
  
  # --------------------------------------------------------------------------
  # Security Implications
  # --------------------------------------------------------------------------
  
  security_implications:
    
    model_interpretability:
      
      advantage: "Logistic regression weights show feature importance"
      
      example: |
        Learned weights for spam detection:
        - exclamation_count: +2.5 (strong spam indicator)
        - email_length: -0.3 (longer emails slightly less likely spam)
        - contains_money: +3.1 (very strong spam indicator)
        
        Can explain to user: "Classified as spam due to 10 exclamations + money words"
      
      security_benefit: |
        - Transparency: Can audit model decisions
        - Trust: Users understand why alert triggered
        - Debugging: Identify which features cause misclassifications
        - Compliance: Explainable AI for regulations (GDPR, etc.)
    
    adversarial_evasion:
      
      attack: "Adversary reverse-engineers model from predictions"
      
      strategy: |
        1. Probe model with many inputs
        2. Observe probability outputs
        3. Infer approximate weights
        4. Craft input that crosses decision boundary
      
      example: |
        Spam filter weights inferred:
        w_exclamation = +2.0
        w_money = +3.0
        
        Malicious email: [exclamations=10, money=5] → P(spam) = 0.95
        Modified: [exclamations=1, money=0] → P(spam) = 0.10
        Evades detection!
      
      defense:
        - "Use many features (harder to manipulate all)"
        - "Use non-linear models (harder to reverse engineer)"
        - "Add noise to predictions (differential privacy)"
        - "Retrain with adversarial examples"
    
    feature_importance_attack:
      
      risk: "Revealing feature weights reveals attack surface"
      
      scenario: |
        Security blog post: "Our malware detector uses these features..."
        Lists: file size, entropy, API calls, network connections
        Weights: entropy (weight=5.0) most important
        
        Adversary response: Pack malware to reduce entropy
        Result: Evades detection
      
      mitigation: |
        - Don't publish feature weights publicly
        - Use ensemble models (multiple diverse models)
        - Rotate features periodically
        - Monitor for evasion attempts
  
  # --------------------------------------------------------------------------
  # Key Takeaways
  # --------------------------------------------------------------------------
  
  key_takeaways:
    
    conceptual_understanding:
      - "Logistic regression = linear model + sigmoid function + cross-entropy loss"
      - "Sigmoid squashes linear output to [0,1] for probability interpretation"
      - "Binary cross-entropy heavily penalizes confident wrong predictions"
      - "Gradient descent finds weights that minimize loss"
      - "Decision boundary is hyperplane: w·x + b = 0"
    
    practical_skills:
      - "Implement logistic regression from scratch using only NumPy"
      - "Derive and compute gradients for gradient descent"
      - "Train model with gradient descent (forward pass, loss, backward pass, update)"
      - "Tune learning rate to ensure convergence"
      - "Interpret learned weights as feature importance"
    
    security_mindset:
      - "Interpretable models better for security (can explain decisions)"
      - "Feature weights reveal attack surface (adversary knows what to manipulate)"
      - "Linear boundaries vulnerable to evasion (adversary crosses boundary easily)"
      - "Regularization helps prevent overfitting to poisoned data"
      - "Always scale features (improves convergence and robustness)"
    
    remember_this:
      - "Logistic regression is foundation of neural networks (stack these = deep learning)"
      - "Gradient descent is foundation of all modern ML (same algorithm, different models)"
      - "You now understand how training works from first principles"
    
    next_steps:
      - "Next section: Training loop and convergence (when to stop training, debugging)"
      - "Connect to security: Section 11 covers evaluation metrics (precision, recall, ROC)"
      - "You've built your first real classifier from scratch!"

---
