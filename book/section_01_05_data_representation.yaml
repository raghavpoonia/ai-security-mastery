# section_01_05_data_representation.yaml

---
document_info:
  chapter: "01"
  section: "05"
  title: "Data Representation and Features"
  version: "1.0.0"
  author: "Raghav Dinesh"
  github: "github.com/raghavpoonia"
  license: "MIT"
  created: "2025-12-30"
  estimated_pages: 6
  tags: ["feature-engineering", "data-representation", "feature-vectors", "text-features", "encoding"]

# ============================================================================
# SECTION 1.05: DATA REPRESENTATION AND FEATURES
# ============================================================================

section_01_05_data_representation:
  
  # --------------------------------------------------------------------------
  # Overview and Context
  # --------------------------------------------------------------------------
  
  overview: |
    Machine learning models don't understand emails, log files, or network traffic. 
    They understand numbers. Specifically, they understand vectors - ordered lists 
    of numbers. Your job as an ML engineer is to convert messy real-world data 
    (text, timestamps, IP addresses, user behavior) into meaningful numerical 
    representations that models can learn from.
    
    This transformation from raw data to feature vectors is called feature engineering, 
    and it's often the difference between a model that works and one that fails. 
    Good features make patterns obvious to the model. Bad features hide patterns 
    or introduce noise.
    
    For security, this matters because adversaries exploit your feature representations. 
    They craft inputs that look normal in feature space but are malicious in reality. 
    They find blind spots where your features don't capture important signals. They 
    reverse-engineer your features to evade detection.
    
    This section teaches you how to represent different types of data as features, 
    what makes a good feature, and how to avoid common pitfalls that create security 
    vulnerabilities.
  
  why_this_matters: |
    Security context:
    - Spam filter: Must convert email text → feature vector
    - Intrusion detection: Must convert network packets → feature vector
    - Malware detection: Must convert binary/behavior → feature vector
    - Prompt injection detection: Must convert user input → feature vector
    
    Poor feature representation:
    - Model can't learn patterns (high error rate)
    - Adversaries find evasion techniques (false negatives)
    - Features leak sensitive information (privacy violations)
    - Model is biased or unfair (discrimination)
    
    Good feature representation:
    - Captures relevant patterns clearly
    - Robust to adversarial manipulation
    - Preserves privacy when needed
    - Generalizes to new data
  
  # --------------------------------------------------------------------------
  # Core Concept 1: Feature Vectors
  # --------------------------------------------------------------------------
  
  feature_vectors:
    
    what_is_feature_vector: |
      A feature vector is an ordered list of numbers representing one data sample.
      
      Format: x = [x₁, x₂, x₃, ..., xₙ]
      
      Where:
      - x is the feature vector
      - Each xᵢ is a feature (a measurable property)
      - n is the number of features (dimensionality)
      
      Each row in your dataset is one feature vector.
      Each column is one feature across all samples.
    
    simple_example:
      
      problem: "Classify email as spam or not spam"
      
      raw_email: |
        Subject: Congratulations! You won $1,000,000!!!
        Body: Click here to claim your prize NOW!!!
        From: winner@prizes.com
        
      features_to_extract:
        - "Number of exclamation marks"
        - "Number of capital letters"
        - "Email length (characters)"
        - "Contains word 'prize'"
        - "Contains word 'click'"
        - "Sender domain is common provider (gmail, yahoo)"
      
      feature_vector: "[15, 12, 87, 1, 1, 0]"
      
      interpretation:
        - "x₁ = 15 exclamation marks"
        - "x₂ = 12 capital letters"
        - "x₃ = 87 characters total"
        - "x₄ = 1 (contains 'prize')"
        - "x₅ = 1 (contains 'click')"
        - "x₆ = 0 (not common email provider)"
    
    numpy_representation: |
      import numpy as np
      
      # Single email represented as feature vector
      email_features = np.array([15, 12, 87, 1, 1, 0])
      
      # Multiple emails represented as matrix (rows = samples, columns = features)
      dataset = np.array([
          [15, 12, 87, 1, 1, 0],  # Email 1 (spam)
          [2,  3,  45, 0, 0, 1],  # Email 2 (not spam)
          [20, 18, 120, 1, 1, 0], # Email 3 (spam)
          [1,  2,  60, 0, 0, 1],  # Email 4 (not spam)
      ])
      
      # Shape: (n_samples, n_features)
      print(dataset.shape)  # (4, 6) - 4 emails, 6 features each
      
      # Access individual features
      exclamation_counts = dataset[:, 0]  # First column (feature 1)
      print(exclamation_counts)  # [15, 2, 20, 1]
    
    feature_space_intuition: |
      Think of feature space as a multi-dimensional space where each feature is an axis.
      
      For 2 features (exclamation marks, capital letters):
      - 2D space: x-axis = exclamation marks, y-axis = capital letters
      - Each email is a point in this space
      - Spam emails cluster in one region (high exclamation, high capitals)
      - Normal emails cluster elsewhere (low exclamation, low capitals)
      
      Model's job: Draw boundary separating spam region from normal region
      
      For 6 features: 6-dimensional space (hard to visualize, but same concept)
      For 1000 features: 1000-dimensional space (common in text classification)
  
  # --------------------------------------------------------------------------
  # Core Concept 2: Types of Features
  # --------------------------------------------------------------------------
  
  types_of_features:
    
    numerical_features:
      
      description: "Already numbers - can use directly or with minimal processing"
      
      continuous:
        definition: "Can take any value in a range (real numbers)"
        examples:
          - "Email length: 45.7 characters"
          - "API response time: 123.4 milliseconds"
          - "File size: 2.5 MB"
          - "User session duration: 18.3 minutes"
        
        properties:
          - "Infinite possible values between any two points"
          - "Can compute mean, median, standard deviation"
          - "Can measure distance between values"
        
        numpy_example: |
          # Continuous numerical features
          response_times = np.array([120.5, 45.3, 200.1, 89.7])
          file_sizes = np.array([2.5, 1.8, 10.2, 0.5])  # MB
          
          # Can do arithmetic operations
          avg_response = np.mean(response_times)
          max_file_size = np.max(file_sizes)
      
      discrete:
        definition: "Can only take specific integer values"
        examples:
          - "Number of failed login attempts: 3"
          - "Port number: 443"
          - "HTTP status code: 404"
          - "Number of exclamation marks: 5"
        
        properties:
          - "Countable, distinct values"
          - "Often non-negative integers"
          - "Can still compute mean, but median might be more meaningful"
        
        numpy_example: |
          # Discrete numerical features
          failed_logins = np.array([0, 2, 5, 1, 0, 3])
          http_codes = np.array([200, 404, 500, 200, 403])
          
          # Count frequency of each value
          unique, counts = np.unique(http_codes, return_counts=True)
          print(dict(zip(unique, counts)))  # {200: 2, 403: 1, 404: 1, 500: 1}
    
    categorical_features:
      
      description: "Discrete labels or categories - must be encoded as numbers"
      
      nominal:
        definition: "Categories with no inherent order"
        examples:
          - "Email provider: [gmail, yahoo, outlook, other]"
          - "HTTP method: [GET, POST, PUT, DELETE]"
          - "IP country: [US, UK, CN, RU]"
          - "File type: [exe, dll, pdf, docx]"
        
        encoding_problem: |
          Can't use category names directly. Model needs numbers.
          
          Bad idea: Assign arbitrary numbers
          - gmail=0, yahoo=1, outlook=2, other=3
          
          Problem: Implies ordering (gmail < yahoo < outlook)
          Model might learn fake pattern: "outlook (2) is between gmail (0) and other (3)"
          This is nonsense - categories have no inherent order!
        
        solution_one_hot_encoding: |
          Create binary feature for each category (1 = yes, 0 = no)
          
          Original: [gmail, yahoo, gmail, outlook]
          
          One-hot encoded:
          is_gmail   is_yahoo   is_outlook   is_other
          1          0          0            0          # gmail
          0          1          0            0          # yahoo
          1          0          0            0          # gmail
          0          0          1            0          # outlook
        
        numpy_implementation: |
          # One-hot encoding from scratch
          def one_hot_encode(categories):
              unique_cats = np.unique(categories)
              n_samples = len(categories)
              n_categories = len(unique_cats)
              
              # Create mapping: category -> index
              cat_to_idx = {cat: idx for idx, cat in enumerate(unique_cats)}
              
              # Initialize one-hot matrix
              one_hot = np.zeros((n_samples, n_categories))
              
              # Fill in 1s where category matches
              for i, cat in enumerate(categories):
                  idx = cat_to_idx[cat]
                  one_hot[i, idx] = 1
              
              return one_hot, unique_cats
          
          # Example
          email_providers = np.array(['gmail', 'yahoo', 'gmail', 'outlook'])
          encoded, categories = one_hot_encode(email_providers)
          
          print(encoded)
          # [[1. 0. 0.]   # gmail
          #  [0. 0. 1.]   # yahoo
          #  [1. 0. 0.]   # gmail
          #  [0. 1. 0.]]  # outlook
      
      ordinal:
        definition: "Categories with meaningful order"
        examples:
          - "Threat severity: [low, medium, high, critical]"
          - "User role: [guest, user, admin, superadmin]"
          - "Alert priority: [P4, P3, P2, P1]"
          - "Confidence: [low, medium, high]"
        
        encoding_approach: |
          Can use integer encoding because order matters:
          low=0, medium=1, high=2, critical=3
          
          Model can learn: critical (3) > high (2) > medium (1)
          This makes sense because ordering is meaningful.
        
        numpy_implementation: |
          # Ordinal encoding
          severities = np.array(['low', 'high', 'medium', 'critical', 'low'])
          
          # Define ordering
          severity_map = {'low': 0, 'medium': 1, 'high': 2, 'critical': 3}
          
          # Encode
          encoded = np.array([severity_map[s] for s in severities])
          print(encoded)  # [0, 2, 1, 3, 0]
        
        warning: |
          Only use ordinal encoding when order is truly meaningful.
          If unsure, use one-hot encoding (safer default).
    
    binary_features:
      
      description: "True/False, Yes/No, Present/Absent - encode as 1/0"
      
      examples:
        - "Email contains 'viagra': 1 (yes) or 0 (no)"
        - "User is admin: 1 (yes) or 0 (no)"
        - "HTTPS enabled: 1 (yes) or 0 (no)"
        - "File is encrypted: 1 (yes) or 0 (no)"
      
      numpy_implementation: |
        # Binary features
        contains_viagra = np.array([1, 0, 0, 1, 0])  # 1=yes, 0=no
        is_admin = np.array([0, 0, 1, 0, 0])
        https_enabled = np.array([1, 1, 0, 1, 1])
        
        # Stack into feature matrix
        features = np.column_stack([contains_viagra, is_admin, https_enabled])
        print(features)
        # [[1 0 1]
        #  [0 0 1]
        #  [0 1 0]
        #  [1 0 1]
        #  [0 0 1]]
      
      tip: "Binary features are already in perfect format for ML - no transformation needed"
    
    text_features:
      
      challenge: |
        Text is unstructured - can't use directly as features.
        
        Need to convert: "Free prize! Click now!" → [x₁, x₂, ..., xₙ]
      
      approach_1_bag_of_words:
        
        concept: |
          Represent text as word counts, ignoring order.
          
          Vocabulary: All unique words across all documents
          Feature: Count of each vocabulary word in this document
        
        example:
          documents:
            - "free prize click"
            - "prize click now"
            - "free click click"
          
          vocabulary: "['click', 'free', 'now', 'prize']  # alphabetically sorted"
          
          feature_vectors:
            doc1: "[1, 1, 0, 1]  # 1 click, 1 free, 0 now, 1 prize"
            doc2: "[1, 0, 1, 1]  # 1 click, 0 free, 1 now, 1 prize"
            doc3: "[2, 1, 0, 0]  # 2 clicks, 1 free, 0 now, 0 prize"
        
        numpy_implementation: |
          # Bag-of-words from scratch
          def bag_of_words(documents):
              # Tokenize: split into words, lowercase
              tokenized = [doc.lower().split() for doc in documents]
              
              # Build vocabulary: all unique words
              vocabulary = sorted(set(word for doc in tokenized for word in doc))
              vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}
              
              # Count words in each document
              n_docs = len(documents)
              n_vocab = len(vocabulary)
              bow = np.zeros((n_docs, n_vocab))
              
              for i, doc in enumerate(tokenized):
                  for word in doc:
                      idx = vocab_to_idx[word]
                      bow[i, idx] += 1
              
              return bow, vocabulary
          
          # Example
          docs = ['free prize click', 'prize click now', 'free click click']
          bow_matrix, vocab = bag_of_words(docs)
          
          print("Vocabulary:", vocab)
          print("BoW matrix:")
          print(bow_matrix)
          # [[1. 1. 0. 1.]
          #  [1. 0. 1. 1.]
          #  [2. 1. 0. 0.]]
        
        limitations:
          - "Loses word order: 'not bad' and 'bad not' look identical"
          - "Ignores context: 'free' in 'free trial' vs 'virus-free'"
          - "Vocabulary can be huge (10k-100k words)"
          - "Most features are zero (sparse matrix)"
      
      approach_2_tf_idf:
        
        concept: |
          TF-IDF = Term Frequency × Inverse Document Frequency
          
          Intuition: Weight words by importance
          - Common words (the, and, is) → low weight
          - Rare but informative words (viagra, malware) → high weight
          
          TF: How often word appears in THIS document
          IDF: How rare word is across ALL documents
        
        formulas:
          tf: "TF(word, doc) = count(word in doc) / total_words_in_doc"
          idf: "IDF(word) = log(total_documents / documents_containing_word)"
          tfidf: "TF-IDF(word, doc) = TF × IDF"
        
        example:
          corpus: "3 documents total"
          word: "'free'"
          
          document_1:
            text: "'free prize free click'  (4 words)"
            tf: "2/4 = 0.5  ('free' appears 2 times out of 4)"
          
          all_documents:
            doc1: "contains 'free'"
            doc2: "doesn't contain 'free'"
            doc3: "contains 'free'"
          
          idf: "log(3/2) = log(1.5) = 0.405"
          
          tfidf: "0.5 × 0.405 = 0.203"
        
        interpretation: |
          Common words (appear in all documents) → IDF near 0 → TF-IDF near 0
          Rare words (appear in few documents) → IDF high → TF-IDF high
          
          This downweights common words and emphasizes distinctive words.
        
        numpy_implementation: |
          # TF-IDF from scratch (simplified)
          def tf_idf(documents):
              # First get bag-of-words
              bow, vocab = bag_of_words(documents)
              n_docs, n_vocab = bow.shape
              
              # Compute TF: normalize by document length
              doc_lengths = bow.sum(axis=1, keepdims=True)
              tf = bow / (doc_lengths + 1e-10)  # avoid division by zero
              
              # Compute IDF: log(total_docs / docs_containing_word)
              docs_with_word = (bow > 0).sum(axis=0)
              idf = np.log(n_docs / (docs_with_word + 1))
              
              # Compute TF-IDF
              tfidf = tf * idf
              
              return tfidf, vocab
          
          # Example
          docs = [
              'free prize click',
              'prize click now',
              'free click click'
          ]
          tfidf_matrix, vocab = tf_idf(docs)
          
          print("Vocabulary:", vocab)
          print("TF-IDF matrix:")
          print(tfidf_matrix)
        
        benefit: "Automatically identifies important words without manual feature engineering"
  
  # --------------------------------------------------------------------------
  # Core Concept 3: Feature Engineering Principles
  # --------------------------------------------------------------------------
  
  feature_engineering_principles:
    
    what_makes_good_feature:
      
      informative:
        definition: "Feature helps distinguish between classes"
        
        example:
          problem: "Spam detection"
          good_feature: "Number of times 'viagra' appears (spams have high count)"
          bad_feature: "Email contains '@' symbol (all emails have this)"
        
        test: "Compute correlation between feature and label. High correlation = informative."
      
      independent:
        definition: "Features provide different information (not redundant)"
        
        example:
          problem: "Fraud detection"
          redundant:
            - "Transaction amount in USD"
            - "Transaction amount in cents (same info, different units)"
          better:
            - "Transaction amount"
            - "Transaction frequency (different info)"
        
        issue: |
          Redundant features waste computation and can confuse some models.
          Feature selection helps remove redundancy (covered in Section 23).
      
      robust:
        definition: "Feature stable under noise and adversarial manipulation"
        
        example:
          problem: "Malware detection"
          fragile: "Exact function name 'evil_function' (easily renamed)"
          robust: "Number of suspicious API calls (harder to hide)"
        
        security_critical: |
          Adversaries actively try to evade detection by manipulating features.
          Use features that capture behavior, not surface characteristics.
      
      efficient:
        definition: "Feature cheap to compute in production"
        
        example:
          expensive: "Deep static analysis of binary (takes 30 seconds)"
          cheap: "File size and entropy (takes milliseconds)"
        
        tradeoff: |
          More features = better accuracy but slower inference.
          Production systems need <50ms response time.
          Feature selection critical for real-time detection.
    
    domain_knowledge_importance:
      
      principle: |
        Best features come from understanding the problem domain.
        Generic features (word counts) work okay.
        Domain-specific features (malicious API sequences) work much better.
      
      example_spam_detection:
        
        generic_features:
          - "Word counts (bag-of-words)"
          - "Email length"
          - "Number of punctuation marks"
        
        domain_specific_features:
          - "Email sent from recently registered domain (< 30 days old)"
          - "Sender IP in known spam blocklist"
          - "Contains money amounts ($, €, £) combined with urgency words"
          - "Reply-to address different from sender address"
          - "Contains shortened URLs (bit.ly, tinyurl)"
        
        why_domain_features_better: |
          They encode security knowledge: "Spammers use fresh domains to avoid blocklists"
          Machine learning discovers: "Correlation between domain age and spam"
          
          Domain features give model a head start with expert knowledge.
      
      example_intrusion_detection:
        
        generic_features:
          - "Packet size"
          - "Number of packets"
          - "Source/destination IPs"
        
        domain_specific_features:
          - "Port scan pattern: Many destination ports, same source IP"
          - "Beaconing: Periodic connections to same external IP"
          - "Volumetric anomaly: 10x normal traffic for this host"
          - "Protocol violation: HTTP request with SQL commands"
          - "Lateral movement: Admin access attempts across many hosts"
        
        encoding_attacker_behavior: |
          These features capture known attack patterns from MITRE ATT&CK.
          Model learns variations and combinations of these patterns.
    
    curse_of_dimensionality:
      
      problem: |
        As number of features increases, data becomes sparse in feature space.
        
        Intuition:
        - 1D: 10 points cover line well
        - 2D: 10 points leave gaps in plane
        - 3D: 10 points barely cover cube
        - 1000D: 10 points are lost in hypercube
      
      consequence: |
        More features ≠ better performance
        
        With limited data:
        - Model can't learn reliable patterns
        - Overfitting becomes severe
        - Need exponentially more data as features increase
      
      rule_of_thumb: "Need at least 10 samples per feature (preferably 100+)"
      
      example:
        scenario: "1000 features, 500 training samples"
        ratio: "0.5 samples per feature"
        conclusion: "Severe overfitting guaranteed"
        solution: "Feature selection - reduce to top 50 features"
      
      mitigation_strategies:
        - "Feature selection: Keep only most informative features"
        - "Dimensionality reduction: PCA, autoencoder (Section 22)"
        - "Regularization: Penalize complex models (Section 14)"
        - "Collect more data: Always the best solution"
  
  # --------------------------------------------------------------------------
  # Practical Implementation: Feature Extraction Toolkit
  # --------------------------------------------------------------------------
  
  practical_implementation:
    
    complete_feature_extractor: |
      # Feature extraction toolkit for security logs
      import numpy as np
      from collections import Counter
      import re
      
      class FeatureExtractor:
          """
          Extract features from security logs for ML classification
          """
          
          def __init__(self):
              self.vocabulary = None
              self.vocab_to_idx = None
          
          def extract_numerical_features(self, text):
              """Extract basic numerical features from text"""
              features = {}
              
              # Length features
              features['length'] = len(text)
              features['word_count'] = len(text.split())
              
              # Character type counts
              features['uppercase_count'] = sum(1 for c in text if c.isupper())
              features['digit_count'] = sum(1 for c in text if c.isdigit())
              features['special_char_count'] = sum(1 for c in text if not c.isalnum() and not c.isspace())
              
              # Specific character counts
              features['exclamation_count'] = text.count('!')
              features['question_count'] = text.count('?')
              features['dollar_count'] = text.count('$')
              
              return features
          
          def extract_binary_features(self, text):
              """Extract binary (yes/no) features"""
              features = {}
              
              # Suspicious keywords
              suspicious_words = ['free', 'prize', 'click', 'winner', 'urgent', 
                                 'viagra', 'loan', 'credit', 'cash']
              
              for word in suspicious_words:
                  features[f'contains_{word}'] = int(word.lower() in text.lower())
              
              # Patterns
              features['has_url'] = int(bool(re.search(r'http[s]?://', text)))
              features['has_email'] = int(bool(re.search(r'\b[\w.-]+@[\w.-]+\.\w+\b', text)))
              features['has_phone'] = int(bool(re.search(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', text)))
              
              return features
          
          def extract_categorical_features(self, metadata):
              """Extract and encode categorical features (one-hot)"""
              features = {}
              
              # Example: Email provider (one-hot encoded)
              provider = metadata.get('email_provider', 'other')
              providers = ['gmail', 'yahoo', 'outlook', 'other']
              
              for p in providers:
                  features[f'provider_{p}'] = int(provider == p)
              
              return features
          
          def fit_vocabulary(self, documents):
              """Build vocabulary from training documents"""
              all_words = []
              for doc in documents:
                  words = doc.lower().split()
                  all_words.extend(words)
              
              # Keep top N most frequent words
              word_counts = Counter(all_words)
              top_words = [word for word, count in word_counts.most_common(100)]
              
              self.vocabulary = sorted(top_words)
              self.vocab_to_idx = {word: idx for idx, word in enumerate(self.vocabulary)}
          
          def extract_bow_features(self, text):
              """Extract bag-of-words features"""
              if self.vocabulary is None:
                  raise ValueError("Must call fit_vocabulary first")
              
              words = text.lower().split()
              bow = np.zeros(len(self.vocabulary))
              
              for word in words:
                  if word in self.vocab_to_idx:
                      idx = self.vocab_to_idx[word]
                      bow[idx] += 1
              
              return bow
          
          def extract_all_features(self, text, metadata=None):
              """Extract complete feature vector"""
              all_features = []
              
              # Numerical features
              num_features = self.extract_numerical_features(text)
              all_features.extend(num_features.values())
              
              # Binary features
              bin_features = self.extract_binary_features(text)
              all_features.extend(bin_features.values())
              
              # Categorical features (if metadata provided)
              if metadata:
                  cat_features = self.extract_categorical_features(metadata)
                  all_features.extend(cat_features.values())
              
              # Bag-of-words features (if vocabulary fitted)
              if self.vocabulary:
                  bow = self.extract_bow_features(text)
                  all_features.extend(bow)
              
              return np.array(all_features)
      
      # Example usage
      extractor = FeatureExtractor()
      
      # Fit vocabulary on training data
      training_texts = [
          'free prize click now',
          'meeting tomorrow at 2pm',
          'urgent winner claim prize'
      ]
      extractor.fit_vocabulary(training_texts)
      
      # Extract features from new text
      new_text = "Congratulations! You won a free prize! Click here NOW!"
      features = extractor.extract_all_features(new_text)
      
      print(f"Feature vector shape: {features.shape}")
      print(f"First 10 features: {features[:10]}")
  
  # --------------------------------------------------------------------------
  # Common Mistakes and Security Implications
  # --------------------------------------------------------------------------
  
  common_mistakes:
    
    mistake_1:
      error: "Using raw categorical values as numbers"
      
      example: |
        Email providers: gmail=1, yahoo=2, outlook=3
        
        Problem: Model thinks outlook (3) = gmail (1) + yahoo (2)
        This is nonsense - categories don't have arithmetic relationships.
      
      fix: "Use one-hot encoding for nominal categories"
      
      security_risk: |
        Model learns spurious patterns based on arbitrary numbering.
        Adversary can exploit: Change provider from 1→3, evade detection.
    
    mistake_2:
      error: "Including target variable in features (data leakage)"
      
      example: |
        Predicting spam, but include feature: "is_in_spam_folder" (1/0)
        
        Problem: This feature is THE ANSWER. Of course spam is in spam folder!
        Model achieves 100% accuracy on training data but fails on new data.
      
      fix: |
        Only use features available at prediction time, BEFORE knowing answer.
        
        Rule: If you don't have this feature when making real predictions, 
        don't include it in training.
      
      security_risk: |
        Model appears to work perfectly in testing but completely fails in production.
        Adversaries bypass "trained" detector because it never actually learned patterns.
    
    mistake_3:
      error: "Using feature values that leak sensitive information"
      
      example: |
        Predicting medical diagnosis using patient SSN as feature.
        
        Problem: SSN is unique identifier - model memorizes each patient.
        Zero generalization to new patients. Privacy violation.
      
      fix: "Remove direct identifiers. Use only medically relevant features."
      
      security_risk: |
        Model stores training data in weights (memorization).
        Adversary can extract training data via model inversion attacks.
        Privacy laws (GDPR, HIPAA) violated.
    
    mistake_4:
      error: "Not handling missing values properly"
      
      example: |
        Feature: "Time since last login" (minutes)
        Missing value: -1 (user never logged in before)
        
        Problem: Model learns -1 is meaningful number, not missing indicator.
        Patterns corrupted by fake -1 values.
      
      fix: |
        Strategy 1: Separate binary feature "has_logged_in_before" (0/1)
        Strategy 2: Impute (fill) with median time for known values
        Strategy 3: Use separate model for users with/without login history
      
      implementation: |
        # Handle missing values explicitly
        def handle_missing_time_since_login(values):
            # Split into binary indicator + imputed value
            has_value = (values >= 0).astype(int)
            
            # Impute missing with median of known values
            known_values = values[values >= 0]
            median_time = np.median(known_values) if len(known_values) > 0 else 0
            
            imputed_values = np.where(values >= 0, values, median_time)
            
            # Return both features
            return has_value, imputed_values
        
        # Example
        times = np.array([30, 45, -1, 60, -1, 20])  # -1 = missing
        has_login, login_times = handle_missing_time_since_login(times)
        
        print("Has previous login:", has_login)  # [1 1 0 1 0 1]
        print("Time since login:", login_times)   # [30 45 40 60 40 20] (40 = median)
  
  # --------------------------------------------------------------------------
  # Security Implications
  # --------------------------------------------------------------------------
  
  security_implications:
    
    adversarial_feature_manipulation:
      
      attack: "Adversary crafts input to manipulate features"
      
      example:
        detector: "Spam filter using 'viagra' count as feature"
        attack: "Replace 'viagra' with 'v1agra' or 'v!agra'"
        result: "Feature value = 0, evades detection"
      
      defense: |
        Use robust features that capture behavior, not surface strings:
        - Bag-of-words with character n-grams (captures misspellings)
        - Embeddings (semantic similarity, not exact match)
        - Behavioral features (access patterns, not content)
    
    feature_inference_attack:
      
      attack: "Adversary reverse-engineers your features from model behavior"
      
      example:
        observation: "Model triggers on emails with 'prize' but not 'reward'"
        inference: "Detector uses exact word match, not semantic similarity"
        evasion: "Use synonyms: 'reward', 'bonus', 'gift' instead of 'prize'"
      
      defense: |
        - Use semantic features (embeddings) instead of exact matches
        - Combine multiple features (harder to infer all)
        - Add noise to features (differential privacy)
        - Regularly retrain with adversarial examples
    
    privacy_leakage_through_features:
      
      risk: "Features encode sensitive information that can be extracted"
      
      example:
        feature: "Email contains 'cancer', 'medication', 'hospital'"
        leakage: "Binary features reveal medical information about user"
        attack: "Model inversion reconstructs original email from features"
      
      mitigation:
        - "Avoid features that directly encode sensitive attributes"
        - "Use aggregated statistics instead of individual data points"
        - "Apply differential privacy: Add calibrated noise to features"
        - "Use homomorphic encryption for private features (advanced)"
    
    distribution_shift_via_poisoning:
      
      attack: "Adversary injects data to shift feature distributions"
      
      example:
        baseline: "Average email length = 100 words"
        attack: "Inject 1000 spam emails with length = 10,000 words"
        result: "Model learns 'long email = normal', short spam evades"
      
      detection: |
        Monitor feature distributions over time:
        - Track mean, median, std dev of each feature
        - Alert if distribution shifts significantly
        - Retrain with poisoned samples removed
      
      prevention: |
        - Robust statistics: Use median instead of mean (resistant to outliers)
        - Outlier detection: Remove extreme feature values before training
        - Trusted data sources: Only train on verified samples
  
  # --------------------------------------------------------------------------
  # Key Takeaways
  # --------------------------------------------------------------------------
  
  key_takeaways:
    
    conceptual_understanding:
      - "Feature vectors convert real-world data to numbers ML models can process"
      - "One-hot encoding for nominal categories, ordinal encoding for ordered categories"
      - "Bag-of-words and TF-IDF convert text to numerical features"
      - "Good features are informative, independent, robust, and efficient to compute"
      - "Domain knowledge creates better features than generic statistics"
    
    practical_skills:
      - "Build feature extraction pipelines for different data types (text, categorical, numerical)"
      - "Implement bag-of-words and TF-IDF from scratch in NumPy"
      - "Handle missing values explicitly with separate indicators or imputation"
      - "Avoid data leakage by only using features available at prediction time"
      - "Monitor feature distributions to detect poisoning attacks"
    
    security_mindset:
      - "Adversaries manipulate surface features - use robust behavioral features instead"
      - "Features can leak sensitive information - minimize privacy exposure"
      - "Feature engineering is attack surface - adversary reverse-engineers your features"
      - "Distribution shifts indicate poisoning - monitor statistics continuously"
      - "Curse of dimensionality worsens with poisoned data - use feature selection"
    
    remember_this:
      - "Features are how models see the world. Bad features = blind model."
      - "Security is cat-and-mouse: Adversary studies your features to evade detection."
      - "Best features encode attacker BEHAVIOR (hard to hide) not ARTIFACTS (easy to change)."
    
    next_steps:
      - "Next section: Data preprocessing - normalization, scaling, handling outliers"
      - "Connect to security: Section 23 covers advanced feature engineering for detection"
      - "Foundation building: You can now convert raw data → feature vectors for ML"

---
