# chapter_01_index.yaml
---
document_info:
  chapter: "01"
  title: "Machine Learning Fundamentals"
  version: "1.0.0"
  author: "Raghav Dinesh"
  github: "github.com/raghavpoonia"
  license: "MIT"
  created: "2025-12-29"
  estimated_pages: 168
  tags: ["machine-learning", "foundations", "numpy", "from-scratch", "supervised-learning"]

chapter_01_index:
  
  chapter_overview:
    
    purpose: |
      This chapter builds your machine learning foundation from absolute zero. 
      You'll learn not just how to use ML libraries, but how machine learning 
      actually works under the hood - the mathematics, the algorithms, the 
      optimization, and most importantly, where things break.
      
      This matters for AI security because you cannot secure what you don't 
      understand. Adversaries exploit the mechanics of gradient descent, the 
      properties of loss functions, and the vulnerabilities in training pipelines. 
      High-level APIs like TensorFlow abstract these away. We won't.
      
      Unlike typical ML courses that jump straight to PyTorch, we implement 
      everything from scratch using only NumPy. You'll build logistic regression 
      by hand, implement gradient descent line by line, and understand backpropagation 
      by coding it yourself. Only after you understand the internals will we use 
      high-level libraries.
      
      By the end of this chapter, you'll have implemented a complete spam classifier 
      from scratch, understand every major ML algorithm, and know exactly where 
      models can be attacked. This is the foundation that makes you dangerous as 
      an AI security engineer.
    
    structure: |
      The chapter follows a clear progression: theory → mathematics → implementation → 
      practice. Each section introduces concepts, shows the math, implements from 
      scratch in NumPy, then applies to real problems. We focus on supervised learning 
      (classification) since most AI security threats target these models.
    
    estimated_total_sections: 28
    estimated_total_pages: 168
    estimated_reading_time: "14-16 hours (Weeks 1-2)"
  
  # --------------------------------------------------------------------------
  # Section Breakdown - All 28 Sections
  # --------------------------------------------------------------------------
  
  sections:
    
    section_01:
      number: "01"
      title: "What is Machine Learning?"
      filename: "section_01_01_what_is_ml.yaml"
      estimated_pages: 6
      
      topics_covered:
        - "Definition: ML vs traditional programming vs AI"
        - "Types of learning: supervised, unsupervised, reinforcement"
        - "The learning pipeline: data → features → model → predictions"
        - "When to use ML (and when not to)"
        - "ML problem types: classification, regression, clustering"
      
      key_deliverables:
        - "Clear mental model of what ML is and isn't"
        - "Understanding of supervised learning focus"
        - "Framework for identifying ML-appropriate problems"
        - "Foundation vocabulary for rest of book"
      
      security_preview:
        - "Every stage of pipeline is attack surface"
        - "Data poisoning, model theft, adversarial inputs"
    
    section_02:
      number: "02"
      title: "Mathematical Foundations: Linear Algebra"
      filename: "section_01_02_linear_algebra.yaml"
      estimated_pages: 7
      
      topics_covered:
        - "Vectors: representation, operations, norms"
        - "Matrices: representation, multiplication, properties"
        - "Dot products and projections"
        - "Matrix transpose, inverse, determinant"
        - "Linear transformations in ML context"
      
      key_deliverables:
        - "Comfortable with vector/matrix operations in NumPy"
        - "Understanding why neural networks use matrix math"
        - "Intuition for high-dimensional spaces"
        - "Foundation for understanding model weights"
    
    section_03:
      number: "03"
      title: "Mathematical Foundations: Calculus for ML"
      filename: "section_01_03_calculus.yaml"
      estimated_pages: 7
      
      topics_covered:
        - "Derivatives: what they represent geometrically"
        - "Partial derivatives and the gradient vector"
        - "Chain rule: foundation of backpropagation"
        - "Gradient descent: walking downhill to minimize loss"
        - "Local vs global minima, saddle points"
      
      key_deliverables:
        - "Understanding how models optimize (gradient descent)"
        - "Ability to compute gradients for simple functions"
        - "Intuition for why chain rule matters"
        - "Foundation for neural network training"
    
    section_04:
      number: "04"
      title: "Mathematical Foundations: Probability and Statistics"
      filename: "section_01_04_probability.yaml"
      estimated_pages: 6
      
      topics_covered:
        - "Probability distributions: normal, binomial, uniform"
        - "Mean, variance, standard deviation"
        - "Bayes' theorem and conditional probability"
        - "Maximum likelihood estimation (MLE)"
        - "Statistical significance and hypothesis testing"
      
      key_deliverables:
        - "Understanding probabilistic predictions"
        - "Ability to interpret model confidence scores"
        - "Foundation for Bayesian approaches"
        - "Statistical thinking for evaluation"

    section_05:
      number: "05"
      title: "Data Representation and Features"
      filename: "section_01_05_data_representation.yaml"
      estimated_pages: 6
      
      topics_covered:
        - "Feature vectors: encoding real-world data as numbers"
        - "Numerical features vs categorical features"
        - "Text features: bag-of-words, TF-IDF"
        - "Feature engineering: creating useful representations"
        - "Curse of dimensionality"
      
      key_deliverables:
        - "Ability to convert raw data to ML-ready format"
        - "Understanding of good vs bad features"
        - "Recognition of dimensionality problems"
        - "Foundation for text classification"
    
    section_06:
      number: "06"
      title: "Data Preprocessing: Cleaning and Normalization"
      filename: "section_01_06_data_preprocessing.yaml"
      estimated_pages: 6
      
      topics_covered:
        - "Handling missing data: strategies and trade-offs"
        - "Outlier detection and treatment"
        - "Feature scaling: normalization vs standardization"
        - "Encoding categorical variables (one-hot, label)"
        - "Train-test contamination prevention"
      
      key_deliverables:
        - "Complete preprocessing pipeline implementation"
        - "Understanding when/how to scale features"
        - "Avoiding data leakage (critical for security)"
        - "Production-ready preprocessing code"
    
    # Continue with remaining 22 sections...
    # (Sections 07-28 follow same detailed structure)
    
    section_27:
      number: "27"
      title: "Building a Spam Classifier from Scratch"
      filename: "section_01_27_spam_classifier.yaml"
      estimated_pages: 7
      
      topics_covered:
        - "Complete project: problem definition to production"
        - "Text preprocessing: tokenization, stopwords, stemming"
        - "Feature extraction: bag-of-words, TF-IDF"
        - "Model selection: Naive Bayes vs logistic regression"
        - "Evaluation and error analysis"
        - "Lessons from building real classifier"
      
      key_deliverables:
        - "Complete working spam classifier (NumPy only)"
        - "Understanding of NLP basics"
        - "Text classification capability"
        - "Practical ML project experience"
      
      implementation:
        - "300+ lines of NumPy code"
        - "Real spam dataset (SMS Spam Collection)"
        - "90%+ accuracy achieved"
    
    section_28:
      number: "28"
      title: "ML Security Considerations"
      filename: "section_01_28_ml_security_intro.yaml"
      estimated_pages: 6
      
      topics_covered:
        - "Where ML models can be attacked"
        - "Training phase: data poisoning, backdoors"
        - "Inference phase: adversarial examples, evasion"
        - "Post-training: model extraction, inversion"
        - "Bridge to Part 2: AI Security Landscape"
      
      key_deliverables:
        - "Security-aware ML development mindset"
        - "Understanding of attack surface"
        - "Preview of upcoming security topics"
        - "Connection to detection engineering"

---
